{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df790c02",
      "metadata": {
        "id": "df790c02"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Hybrid Sentiment Analysis - Google Colab Training\n",
        "# ============================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bc354a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bc354a3",
        "outputId": "074a29db-fbbf-4d46-ea0f-f607a6b901dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Dec  2 12:27:18 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "%pip install transformers datasets gensim scikit-learn xgboost nltk pandas numpy matplotlib seaborn tqdm pyyaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9d61576",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "d9d61576",
        "outputId": "16df1929-601a-4a31-87ab-0486a061779b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'hybrid-sentiment'...\n",
            "remote: Enumerating objects: 161, done.\u001b[K\n",
            "remote: Counting objects: 100% (161/161), done.\u001b[K\n",
            "remote: Compressing objects: 100% (112/112), done.\u001b[K\n",
            "remote: Total 161 (delta 88), reused 111 (delta 42), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (161/161), 93.70 KiB | 4.68 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n",
            "/content/hybrid-sentiment\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom google.colab import files\\nimport zipfile\\n\\nprint(\"Upload hybrid-sentiment.zip\")\\nuploaded = files.upload()\\n\\nzip_name = list(uploaded.keys())[0]\\nwith zipfile.ZipFile(zip_name, \\'r\\') as zip_ref:\\n    zip_ref.extractall(\\'/content/\\')\\n\\n%cd /content/hybrid-sentiment\\n'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!git clone https://github.com/steepcloud/hybrid-sentiment.git\n",
        "%cd hybrid-sentiment\n",
        "\n",
        "# private repo option\n",
        "'''\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "print(\"Upload hybrid-sentiment.zip\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "zip_name = list(uploaded.keys())[0]\n",
        "with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')\n",
        "\n",
        "%cd /content/hybrid-sentiment\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8782cbb7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8782cbb7",
        "outputId": "4a857bb8-5dd3-414a-dae8-99b5f32c32ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 56\n",
            "drwxr-xr-x 8 root root  4096 Dec  2 12:27 .\n",
            "drwxr-xr-x 6 root root  4096 Dec  2 12:27 ..\n",
            "drwxr-xr-x 2 root root  4096 Dec  2 12:27 data\n",
            "drwxr-xr-x 2 root root  4096 Dec  2 12:27 evaluation\n",
            "-rw-r--r-- 1 root root     0 Dec  2 12:27 __init__.py\n",
            "-rw-r--r-- 1 root root 22185 Dec  2 12:27 main.py\n",
            "drwxr-xr-x 4 root root  4096 Dec  2 12:27 models\n",
            "drwxr-xr-x 2 root root  4096 Dec  2 12:27 training\n",
            "drwxr-xr-x 2 root root  4096 Dec  2 12:27 utils\n",
            "drwxr-xr-x 2 root root  4096 Dec  2 12:27 visualization\n"
          ]
        }
      ],
      "source": [
        "# verify\n",
        "!ls -la src/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a25973ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a25973ee",
        "outputId": "179b0f3d-8e89-4d55-9218-c0bd145afae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK data downloaded!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "for package in ['punkt', 'punkt_tab', 'stopwords']:\n",
        "    nltk.download(package, quiet=True)\n",
        "print(\"NLTK data downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cd5504f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cd5504f",
        "outputId": "b3746b26-4c67-46c0-ccdf-766664d0b5b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "CUDA version: 12.6\n",
            "Device: Tesla T4\n",
            "GPU: Tesla T4\n",
            "Memory: 15.8 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")\n",
        "print(f\"Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b4dd927",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1a88c3a1b4eb4f5da77cd58d97c0bd34",
            "523429b6aa624a0480b24ef1653b19e3",
            "0207f73ce0f0410b9b68a65a72cb24e6",
            "66fd4a879a4c419c8ca7044517d9b765",
            "7d8d530d4a8841faa0d477f2c8fefd6a",
            "1a968753818e4e4da167f5d01aa959b0",
            "099499c198d9464daa43a78043343619",
            "a6c18f650f8e457f8963d2ac1ecbae48",
            "0e53d6a5f07e47028f80a12cf3dacc13",
            "7a15726d50844dc2ba75bb6d77587537",
            "6dce79a204114260b115eb439a71e9e7",
            "d33443e6a1b64581b6be8a95a623e6b1",
            "e559284867cf47ed958e0f9d86b7fe72",
            "9e57f585de484a0bbd9ffe99315ff198",
            "83e1fc4837d549d9b8c9c3cc7af05654",
            "0a83d7f251dc42cb8df6c72eb7ae8aab",
            "9e24b077d2554c7487b9a67ae27f2d67",
            "059dfe3d00a847c8a6d17022f2e1a977",
            "09ffa57211724ec98f7fb1e16116ce8a",
            "092ae5d929934c8e88bccf071ce97d64",
            "55c6c956ac1f4c90b99451081351adef",
            "80323394f03d46c9862ab6d1ca0b9324",
            "fb5477d1c8c64562834acd33bfc014ec",
            "78ba506d7c914572a3e2e2261e06e688",
            "f191517558e6419293ad4542aa70dbbe",
            "6af89e966b074b75bddfcca0bf0e80e6",
            "7d0db30d0ac84ac5a48b662afd65325b",
            "27204c08d9c24d11ac6a017697cc9065",
            "332e763c901c4f26bd4abbbb16b56dd7",
            "d6ccaa4056bc48c9b591164d568ae002",
            "9a4470cbc07e425c9965a66e9c95264e",
            "8da7c2d2e5c043e4ac2a3bd9a8d920c6",
            "04fe72afea0b4d00898fd88557bbcdc4",
            "1ba221bca29244b5be5fb5017d3fd18d",
            "938a73db7c4f46ff83adec5d9e0611e1",
            "976ea2578c6a4ff9905825d9c88af369",
            "9a83232aaf64423a972bc8e946038c4f",
            "3720ae1316494edaa83e1b882a740a89",
            "f7b72a9514e846e38281b1ce104dd698",
            "235a48e224ab44c78e930972f026fb42",
            "9a4e71cfd2cb4912a3e9e6b270911706",
            "294826c22bfc45df902c962877d282a0",
            "4ec746a93e7141d396ed22bd7af0f5e9",
            "ca10e6dbb14c43219d350e80181eb481",
            "c6c6fb8437344853ad45276a32ea6e82",
            "556ae0da6ce1455faf111cc60de7c964",
            "680c143cfb6f40028002bb07b51cfcee",
            "55db6a1a09ae44d89f1dde8e869e5090",
            "0fb3f4157bbf4961a3edb1bff3f53d0e",
            "f98c700d3dc7444e94a64bda0e7e97a7",
            "1e2c4b9fc2634e62ba81d818d452598d",
            "b81871f7e76a4d24ab1c6d907bb5e34e",
            "373b60fb4d354dab9a3c5b5b8d6a6fd6",
            "c90501e54c44498898540de0f6c6b51c",
            "afbc1204da624638b59772dfdbf0b748",
            "302f4f0d1f88418d83ac84735aa58fab",
            "faf0e30e6e1049408612aa3a217b7d9a",
            "5a49edac760149c39aa6e443f6b4df9c",
            "4a18beecb809431b9a912aa52100aa1f",
            "be48610c794a4ffe8468bfb61e9de690",
            "f2d44aae8dd24d9080213f186677c05f",
            "862cc9b18dd24cc5aed4f8820ebc8ca2",
            "6f600cc705e94e7c893ace2777246b75",
            "6c821675e7b84e26bc5dacacef7d997b",
            "eefb1ff16819499a8225d6aceeb215da",
            "614b282c8b0647b0becd07ca50ce21f3",
            "ca8cf4fba00b478786dbad16aaeb35fd",
            "ade29563d8cd415bb234fd80266ffada",
            "320796950c3a4d17a99e181f2a26393d",
            "b1dc323a3b5048e38a5017c169474a29",
            "fb5c9a41d33b4bb796a3cd629908743e",
            "d3fd8c8eed624af3afecaa5f3d1d8db0",
            "4259dcaef5454676bd51500ba9440efd",
            "56c475e8323d486da25d522022f3f01e",
            "1527633ac2c14730867a78dece9491bd",
            "263147c7f5e3499986ab689f647b8dc7",
            "63aa8a58a01f447d81425315143f8f52"
          ]
        },
        "id": "7b4dd927",
        "outputId": "6d87a12e-ac3d-4585-a296-1bf52218a3cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading IMDB dataset...\n",
            "Loading IMDb dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a88c3a1b4eb4f5da77cd58d97c0bd34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d33443e6a1b64581b6be8a95a623e6b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb5477d1c8c64562834acd33bfc014ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ba221bca29244b5be5fb5017d3fd18d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "plain_text/unsupervised-00000-of-00001.p(…):   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6c6fb8437344853ad45276a32ea6e82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "302f4f0d1f88418d83ac84735aa58fab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca8cf4fba00b478786dbad16aaeb35fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 22500, Val size: 2500, Test size: 25000\n",
            "\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Training Set Statistics\n",
            "============================================================\n",
            "Total samples: 22500\n",
            "\n",
            "Class Distribution:\n",
            "  Negative (label=0): 11250 (50.00%)\n",
            "  Positive (label=1): 11250 (50.00%)\n",
            "\n",
            "Text Length Statistics (in words):\n",
            "  Mean: 233.86\n",
            "  Median: 174.00\n",
            "  Std Dev: 173.82\n",
            "  Min: 10\n",
            "  Max: 2470\n",
            "  25th percentile: 127.00\n",
            "  75th percentile: 284.00\n",
            "  95th percentile: 596.05\n",
            "  99th percentile: 917.00\n",
            "\n",
            "============================================================\n",
            "Validation Set Statistics\n",
            "============================================================\n",
            "Total samples: 2500\n",
            "\n",
            "Class Distribution:\n",
            "  Negative (label=0): 1250 (50.00%)\n",
            "  Positive (label=1): 1250 (50.00%)\n",
            "\n",
            "Text Length Statistics (in words):\n",
            "  Mean: 233.17\n",
            "  Median: 172.00\n",
            "  Std Dev: 173.01\n",
            "  Min: 18\n",
            "  Max: 1398\n",
            "  25th percentile: 127.00\n",
            "  75th percentile: 284.25\n",
            "  95th percentile: 610.05\n",
            "  99th percentile: 900.02\n",
            "\n",
            "============================================================\n",
            "Test Set Statistics\n",
            "============================================================\n",
            "Total samples: 25000\n",
            "\n",
            "Class Distribution:\n",
            "  Negative (label=0): 12500 (50.00%)\n",
            "  Positive (label=1): 12500 (50.00%)\n",
            "\n",
            "Text Length Statistics (in words):\n",
            "  Mean: 228.53\n",
            "  Median: 172.00\n",
            "  Std Dev: 168.88\n",
            "  Min: 4\n",
            "  Max: 2278\n",
            "  25th percentile: 126.00\n",
            "  75th percentile: 277.00\n",
            "  95th percentile: 582.05\n",
            "  99th percentile: 901.00\n",
            "============================================================\n",
            "\n",
            "IMDB dataset ready for training!\n"
          ]
        }
      ],
      "source": [
        "# Load Dataset (IMDB, Twitter, or Custom)\n",
        "# ============================================================\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/hybrid-sentiment')\n",
        "\n",
        "from src.data.data_loader import DatasetLoader\n",
        "\n",
        "# initialize\n",
        "loader = DatasetLoader(config_path='configs/config.yaml')\n",
        "\n",
        "# dataset type: 'imdb', 'twitter' or 'custom'\n",
        "DATASET = 'imdb'\n",
        "\n",
        "print(f\"Loading {DATASET.upper()} dataset...\")\n",
        "\n",
        "if DATASET == 'imdb':\n",
        "    # load IMDB movie reviews (50k reviews)\n",
        "    train_df, val_df, test_df = loader.load_imdb(use_cache=False)\n",
        "\n",
        "elif DATASET == 'twitter':\n",
        "    # load twitter Sentiment140 (1.6M tweets)\n",
        "    train_df, val_df, test_df = loader.load_twitter(use_cache=False)\n",
        "\n",
        "elif DATASET == 'custom':\n",
        "    # load custom dataset from CSV\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        IN_COLAB = True\n",
        "    except ImportError:\n",
        "        IN_COLAB = False\n",
        "    import os\n",
        "\n",
        "    print(\"\\nUpload your CSV file\")\n",
        "    print(\"Required format:\")\n",
        "    print(\"  - Column 1: 'text' (review/tweet/comment)\")\n",
        "    print(\"  - Column 2: 'label' (0=negative, 1=positive)\")\n",
        "    print(\"\\nExample CSV format:\")\n",
        "    print('  text,label')\n",
        "    print('  \"Great product!\",1')\n",
        "    print('  \"Terrible service.\",0')\n",
        "    print()\n",
        "\n",
        "    if IN_COLAB:\n",
        "        uploaded = files.upload()\n",
        "        csv_filename = list(uploaded.keys())[0]\n",
        "    else:\n",
        "        # for local Jupyter, prompt for file path\n",
        "        csv_filename = input(\"Enter the path to your CSV file: \")\n",
        "\n",
        "    os.makedirs('data/raw', exist_ok=True)\n",
        "    custom_path = f'data/raw/{csv_filename}'\n",
        "    os.rename(csv_filename, custom_path)\n",
        "\n",
        "    print(f\"\\nLoading custom dataset from {custom_path}...\")\n",
        "    train_df, val_df, test_df = loader.load_custom(\n",
        "        train_path=custom_path,\n",
        "        use_cache=True\n",
        "    )\n",
        "\n",
        "    print(f\"  Custom dataset loaded and split:\")\n",
        "    print(f\"  Train: {len(train_df)} samples\")\n",
        "    print(f\"  Val: {len(val_df)} samples\")\n",
        "    print(f\"  Test: {len(test_df)} samples\")\n",
        "\n",
        "else:\n",
        "    raise ValueError(f\"Unknown dataset: {DATASET}. Choose 'imdb', 'twitter', or 'custom'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "loader.get_data_statistics(train_df, \"Training Set\")\n",
        "loader.get_data_statistics(val_df, \"Validation Set\")\n",
        "loader.get_data_statistics(test_df, \"Test Set\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n{DATASET.upper()} dataset ready for training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d2a673",
      "metadata": {
        "id": "68d2a673"
      },
      "outputs": [],
      "source": [
        "dataset_arg = DATASET if DATASET in ['imdb', 'twitter'] else 'imdb'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cade618b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cade618b",
        "outputId": "43c71570-63e7-4981-85bf-5977a0809848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded from configs/config.yaml\n",
            "Random seed set to 42\n",
            "Initialized EmbeddingTrainer\n",
            "  Embedding type: word2vec\n",
            "\n",
            "============================================================\n",
            "Training Embeddings on IMDB\n",
            "============================================================\n",
            "\n",
            "Loading dataset...\n",
            "Loading IMDb dataset...\n",
            "Saved dataset to cache: data/processed/imdb_cache.pkl\n",
            "Train size: 22500, Val size: 2500, Test size: 25000\n",
            "Total texts for training: 50000\n",
            "\n",
            "Preparing corpus...\n",
            "  Total texts: 50000\n",
            "  Building vocabulary...\n",
            "Building vocabulary...\n",
            "Vocabulary size: 20000\n",
            "Most common words: ['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
            "Vocabulary saved to results/embeddings/word2vec/vocab.pkl\n",
            "  Tokenizing texts...\n",
            "    Processed 5000/50000 texts\n",
            "    Processed 10000/50000 texts\n",
            "    Processed 15000/50000 texts\n",
            "    Processed 20000/50000 texts\n",
            "    Processed 25000/50000 texts\n",
            "    Processed 30000/50000 texts\n",
            "    Processed 35000/50000 texts\n",
            "    Processed 40000/50000 texts\n",
            "    Processed 45000/50000 texts\n",
            "    Processed 50000/50000 texts\n",
            "✓ Corpus prepared: 50000 documents\n",
            "  Vocabulary size: 20000\n",
            "\n",
            "============================================================\n",
            "Training Word2Vec Embeddings\n",
            "============================================================\n",
            "Training Word2Vec model...\n",
            "  Algorithm: Skip-gram\n",
            "  Embedding dimension: 300\n",
            "  Window size: 5\n",
            "  Min count: 2\n",
            "  Epochs: 5\n",
            "  Total sentences: 50000\n",
            "  Vocabulary size: 63818\n",
            "✓ Training complete!\n",
            "\n",
            "Word2Vec Model Statistics:\n",
            "  vocab_size: 63818\n",
            "  embedding_dim: 300\n",
            "  window: 5\n",
            "  min_count: 2\n",
            "  algorithm: Skip-gram\n",
            "  epochs: 5\n",
            "  total_words: 6066186\n",
            "\n",
            "✓ Training complete!\n",
            "  Vocabulary size: 63818\n",
            "  Embedding dimension: 300\n",
            "Model saved to results/embeddings/word2vec/word2vec.model\n",
            "Metadata saved to results/embeddings/word2vec/word2vec.pkl\n",
            "\n",
            "============================================================\n",
            "Evaluating Embeddings\n",
            "============================================================\n",
            "\n",
            "Word Similarities:\n",
            "\n",
            "  'good' similar to:\n",
            "    workable: 0.6273\n",
            "    decent: 0.6261\n",
            "    awsome: 0.6251\n",
            "    serviceable: 0.6164\n",
            "    great: 0.6143\n",
            "\n",
            "  'bad' similar to:\n",
            "    terrible: 0.5906\n",
            "    shitty: 0.5791\n",
            "    horrible: 0.5787\n",
            "    redline: 0.5769\n",
            "    awful: 0.5752\n",
            "\n",
            "  'excellent' similar to:\n",
            "    outstanding: 0.7497\n",
            "    exceptional: 0.6977\n",
            "    superb: 0.6943\n",
            "    terrific: 0.6836\n",
            "    fantastic: 0.6507\n",
            "\n",
            "  'terrible' similar to:\n",
            "    horrible: 0.7851\n",
            "    awful: 0.7410\n",
            "    horrendous: 0.7208\n",
            "    atrocious: 0.6796\n",
            "    horrid: 0.6778\n",
            "\n",
            "  'love' similar to:\n",
            "    madly: 0.5535\n",
            "    lovehate: 0.5409\n",
            "    hate: 0.5253\n",
            "    bermuda: 0.5137\n",
            "    poonam: 0.5132\n",
            "\n",
            "  'hate' similar to:\n",
            "    despise: 0.6972\n",
            "    loathe: 0.6595\n",
            "    dislike: 0.6497\n",
            "    adore: 0.5998\n",
            "    hated: 0.5982\n",
            "\n",
            "  'happy' similar to:\n",
            "    hopeful: 0.5624\n",
            "    unhappy: 0.5216\n",
            "    proteins: 0.5124\n",
            "    overjoyed: 0.5086\n",
            "    camper: 0.5032\n",
            "\n",
            "  'sad' similar to:\n",
            "    heartwarming: 0.5671\n",
            "    saddest: 0.5546\n",
            "    regretful: 0.5479\n",
            "    humbling: 0.5425\n",
            "    saddening: 0.5415\n",
            "\n",
            "  'amazing' similar to:\n",
            "    incredible: 0.7121\n",
            "    awesome: 0.6897\n",
            "    astounding: 0.6719\n",
            "    outstanding: 0.6565\n",
            "    spellbinding: 0.6458\n",
            "\n",
            "  'awful' similar to:\n",
            "    terrible: 0.7410\n",
            "    dreadful: 0.6825\n",
            "    horrible: 0.6683\n",
            "    abysmal: 0.6672\n",
            "    atrocious: 0.6654\n",
            "\n",
            "  'best' similar to:\n",
            "    finest: 0.6842\n",
            "    worst: 0.6235\n",
            "    weakest: 0.6201\n",
            "    sexiest: 0.5982\n",
            "    funniest: 0.5962\n",
            "\n",
            "  'worst' similar to:\n",
            "    stupidest: 0.7265\n",
            "    lamest: 0.6728\n",
            "    cheesiest: 0.6725\n",
            "    scariest: 0.6702\n",
            "    weirdest: 0.6679\n",
            "\n",
            "------------------------------------------------------------\n",
            "Word Pair Similarities:\n",
            "  good <-> great: 0.6143\n",
            "  bad <-> terrible: 0.5906\n",
            "  love <-> like: 0.3586\n",
            "  hate <-> dislike: 0.6497\n",
            "  good <-> bad: 0.5669\n",
            "  love <-> hate: 0.5253\n",
            "\n",
            "------------------------------------------------------------\n",
            "Sentiment Word Clusters:\n",
            "\n",
            "  POSITIVE words:\n",
            "    good <-> great: 0.6143\n",
            "    good <-> excellent: 0.5411\n",
            "    good <-> amazing: 0.4190\n",
            "    good <-> wonderful: 0.4864\n",
            "    great <-> excellent: 0.6272\n",
            "    great <-> amazing: 0.5334\n",
            "    great <-> wonderful: 0.6707\n",
            "    excellent <-> amazing: 0.6404\n",
            "    excellent <-> wonderful: 0.6185\n",
            "    amazing <-> wonderful: 0.6000\n",
            "    Average similarity: 0.5751\n",
            "\n",
            "  NEGATIVE words:\n",
            "    bad <-> terrible: 0.5906\n",
            "    bad <-> awful: 0.5752\n",
            "    bad <-> horrible: 0.5787\n",
            "    bad <-> worst: 0.3776\n",
            "    terrible <-> awful: 0.7410\n",
            "    terrible <-> horrible: 0.7851\n",
            "    terrible <-> worst: 0.4496\n",
            "    awful <-> horrible: 0.6683\n",
            "    awful <-> worst: 0.4364\n",
            "    horrible <-> worst: 0.4407\n",
            "    Average similarity: 0.5643\n",
            "Results saved to results/embeddings/word2vec/training_results.pkl\n",
            "\n",
            "✓ Training complete!\n",
            "\n",
            "Metadata:\n",
            "  dataset: imdb\n",
            "  embedding_type: word2vec\n",
            "  corpus_size: 50000\n",
            "  vocab_size: 20000\n",
            "  embedding_dim: 300\n",
            "  timestamp: 20251201_140206\n",
            "Word2Vec embeddings trained\n",
            "  Dataset: IMDB\n"
          ]
        }
      ],
      "source": [
        "# train Word2Vec embeddings\n",
        "\n",
        "!python src/training/train_embeddings.py \\\n",
        "    --dataset {dataset_arg} \\\n",
        "    --embedding word2vec\n",
        "\n",
        "print(f\"Word2Vec embeddings trained\")\n",
        "if DATASET == 'custom':\n",
        "    print(f\"  (using {dataset_arg.upper()} configuration)\")\n",
        "else:\n",
        "    print(f\"  Dataset: {DATASET.upper()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "728485db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "728485db",
        "outputId": "3bed3e59-caea-43c2-e55b-807de358bd8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded from configs/config.yaml\n",
            "Random seed set to 42\n",
            "Using GPU: Tesla T4\n",
            "Initialized EndToEndDLTrainer\n",
            "  Model type: lstm\n",
            "  Device: cuda\n",
            "\n",
            "============================================================\n",
            "Training on IMDB Dataset\n",
            "============================================================\n",
            "\n",
            "Loading dataset...\n",
            "Loaded dataset from cache: data/processed/imdb_cache.pkl\n",
            "\n",
            "Building vocabulary...\n",
            "Building vocabulary...\n",
            "Vocabulary size: 20000\n",
            "Most common words: ['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
            "\n",
            "Creating LSTM model...\n",
            "  ✓ Applied Xavier initialization to classifier\n",
            "  Total parameters: 6,868,738\n",
            "\n",
            "Preparing data loaders...\n",
            "  Train batches: 352\n",
            "  Val batches: 40\n",
            "  Test batches: 391\n",
            "\n",
            "============================================================\n",
            "Training LSTM Model\n",
            "============================================================\n",
            "  Epochs: 10\n",
            "  Learning rate: 0.001\n",
            "  Batch size: 64\n",
            "\n",
            "============================================================\n",
            "Epoch 1/10\n",
            "============================================================\n",
            "Epoch 1: 100% 352/352 [00:17<00:00, 19.74it/s, loss=0.5839, acc=64.77%]\n",
            "\n",
            "Training - Loss: 0.6193, Accuracy: 0.6477\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.7476\n",
            "Precision: 0.7599\n",
            "Recall:    0.7240\n",
            "F1 Score:  0.7415\n",
            "ROC-AUC:   0.8228\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/lstm/lstm_best.pt\n",
            "✓ Best model saved (F1: 0.7415)\n",
            "\n",
            "============================================================\n",
            "Epoch 2/10\n",
            "============================================================\n",
            "Epoch 2: 100% 352/352 [00:17<00:00, 20.52it/s, loss=0.4871, acc=79.44%]\n",
            "\n",
            "Training - Loss: 0.4480, Accuracy: 0.7944\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.8096\n",
            "Precision: 0.7497\n",
            "Recall:    0.9296\n",
            "F1 Score:  0.8300\n",
            "ROC-AUC:   0.9080\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/lstm/lstm_best.pt\n",
            "✓ Best model saved (F1: 0.8300)\n",
            "\n",
            "============================================================\n",
            "Epoch 3/10\n",
            "============================================================\n",
            "Epoch 3: 100% 352/352 [00:16<00:00, 21.58it/s, loss=0.2454, acc=85.20%]\n",
            "\n",
            "Training - Loss: 0.3459, Accuracy: 0.8520\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.8376\n",
            "Precision: 0.7871\n",
            "Recall:    0.9256\n",
            "F1 Score:  0.8507\n",
            "ROC-AUC:   0.9244\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/lstm/lstm_best.pt\n",
            "✓ Best model saved (F1: 0.8507)\n",
            "\n",
            "============================================================\n",
            "Epoch 4/10\n",
            "============================================================\n",
            "Epoch 4: 100% 352/352 [00:17<00:00, 20.65it/s, loss=0.3689, acc=88.59%]\n",
            "\n",
            "Training - Loss: 0.2797, Accuracy: 0.8859\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.8608\n",
            "Precision: 0.9122\n",
            "Recall:    0.7984\n",
            "F1 Score:  0.8515\n",
            "ROC-AUC:   0.9436\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/lstm/lstm_best.pt\n",
            "✓ Best model saved (F1: 0.8515)\n",
            "\n",
            "============================================================\n",
            "Epoch 5/10\n",
            "============================================================\n",
            "Epoch 5: 100% 352/352 [00:17<00:00, 20.14it/s, loss=0.2098, acc=91.18%]\n",
            "\n",
            "Training - Loss: 0.2288, Accuracy: 0.9118\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.8692\n",
            "Precision: 0.8275\n",
            "Recall:    0.9328\n",
            "F1 Score:  0.8770\n",
            "ROC-AUC:   0.9454\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/lstm/lstm_best.pt\n",
            "✓ Best model saved (F1: 0.8770)\n",
            "\n",
            "============================================================\n",
            "Epoch 6/10\n",
            "============================================================\n",
            "Epoch 6: 100% 352/352 [00:16<00:00, 21.13it/s, loss=0.1965, acc=92.70%]\n",
            "\n",
            "Training - Loss: 0.1856, Accuracy: 0.9270\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.8856\n",
            "Precision: 0.8838\n",
            "Recall:    0.8880\n",
            "F1 Score:  0.8859\n",
            "ROC-AUC:   0.9470\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/lstm/lstm_best.pt\n",
            "✓ Best model saved (F1: 0.8859)\n",
            "\n",
            "============================================================\n",
            "Epoch 7/10\n",
            "============================================================\n",
            "Epoch 7: 100% 352/352 [00:16<00:00, 21.20it/s, loss=0.0320, acc=94.19%]\n",
            "\n",
            "Training - Loss: 0.1519, Accuracy: 0.9419\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.8812\n",
            "Precision: 0.8767\n",
            "Recall:    0.8872\n",
            "F1 Score:  0.8819\n",
            "ROC-AUC:   0.9472\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "Epoch 8/10\n",
            "============================================================\n",
            "Epoch 8: 100% 352/352 [00:16<00:00, 21.53it/s, loss=0.1278, acc=95.64%]\n",
            "\n",
            "Training - Loss: 0.1185, Accuracy: 0.9564\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.8768\n",
            "Precision: 0.8618\n",
            "Recall:    0.8976\n",
            "F1 Score:  0.8793\n",
            "ROC-AUC:   0.9460\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "Epoch 9/10\n",
            "============================================================\n",
            "Epoch 9: 100% 352/352 [00:17<00:00, 20.65it/s, loss=0.2346, acc=96.35%]\n",
            "\n",
            "Training - Loss: 0.0966, Accuracy: 0.9635\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.8736\n",
            "Precision: 0.8490\n",
            "Recall:    0.9088\n",
            "F1 Score:  0.8779\n",
            "ROC-AUC:   0.9432\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "Epoch 10/10\n",
            "============================================================\n",
            "Epoch 10: 100% 352/352 [00:16<00:00, 21.59it/s, loss=0.0691, acc=96.96%]\n",
            "\n",
            "Training - Loss: 0.0808, Accuracy: 0.9696\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.8828\n",
            "Precision: 0.9059\n",
            "Recall:    0.8544\n",
            "F1 Score:  0.8794\n",
            "ROC-AUC:   0.9483\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "Training Complete!\n",
            "  Best epoch: 6\n",
            "  Best validation F1: 0.8859\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Evaluating best model on test set...\n",
            "============================================================\n",
            "\n",
            "Test Results:\n",
            "\n",
            "Test\n",
            "==================================================\n",
            "Accuracy:  0.8660\n",
            "Precision: 0.8760\n",
            "Recall:    0.8528\n",
            "F1 Score:  0.8642\n",
            "ROC-AUC:   0.9404\n",
            "==================================================\n",
            "\n",
            "✓ Training complete!\n",
            "\n",
            "Final Test Results:\n",
            "  Accuracy: 0.8660\n",
            "  Precision: 0.8760\n",
            "  Recall: 0.8528\n",
            "  F1 Score: 0.8642\n",
            "  ROC-AUC: 0.9404\n",
            "LSTM model trained on IMDB dataset\n"
          ]
        }
      ],
      "source": [
        "# train LSTM End-to-End\n",
        "\n",
        "!python src/training/train_end_to_end_dl.py \\\n",
        "    --dataset {dataset_arg} \\\n",
        "    --model lstm \\\n",
        "    --epochs 10 \\\n",
        "    --batch_size 64 \\\n",
        "    --lr 0.001\n",
        "\n",
        "print(f\"LSTM model trained on {DATASET.upper()} dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10728f07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10728f07",
        "outputId": "4519516f-22b5-483d-8569-45e0807d24d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded from configs/config.yaml\n",
            "Random seed set to 42\n",
            "Using GPU: Tesla T4\n",
            "Initialized EndToEndDLTrainer\n",
            "  Model type: gru\n",
            "  Device: cuda\n",
            "\n",
            "============================================================\n",
            "Training on IMDB Dataset\n",
            "============================================================\n",
            "\n",
            "Loading dataset...\n",
            "Loaded dataset from cache: data/processed/imdb_cache.pkl\n",
            "\n",
            "Building vocabulary...\n",
            "Building vocabulary...\n",
            "Vocabulary size: 20000\n",
            "Most common words: ['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
            "\n",
            "Creating GRU model...\n",
            "  ✓ Applied Xavier initialization to classifier\n",
            "  Total parameters: 6,659,842\n",
            "\n",
            "Preparing data loaders...\n",
            "  Train batches: 352\n",
            "  Val batches: 40\n",
            "  Test batches: 391\n",
            "\n",
            "============================================================\n",
            "Training GRU Model\n",
            "============================================================\n",
            "  Epochs: 10\n",
            "  Learning rate: 0.0001\n",
            "  Batch size: 64\n",
            "\n",
            "============================================================\n",
            "Epoch 1/10\n",
            "============================================================\n",
            "Epoch 1: 100% 352/352 [00:16<00:00, 21.45it/s, loss=0.9031, acc=50.36%]\n",
            "\n",
            "Training - Loss: 0.9883, Accuracy: 0.5036\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.5020\n",
            "Precision: 0.5010\n",
            "Recall:    0.9552\n",
            "F1 Score:  0.6573\n",
            "ROC-AUC:   0.5378\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/gru/gru_best.pt\n",
            "✓ Best model saved (F1: 0.6573)\n",
            "\n",
            "============================================================\n",
            "Epoch 2/10\n",
            "============================================================\n",
            "Epoch 2: 100% 352/352 [00:17<00:00, 20.50it/s, loss=0.9024, acc=50.09%]\n",
            "\n",
            "Training - Loss: 0.8859, Accuracy: 0.5009\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.5024\n",
            "Precision: 0.5012\n",
            "Recall:    0.9624\n",
            "F1 Score:  0.6592\n",
            "ROC-AUC:   0.5390\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/gru/gru_best.pt\n",
            "✓ Best model saved (F1: 0.6592)\n",
            "\n",
            "============================================================\n",
            "Epoch 3/10\n",
            "============================================================\n",
            "Epoch 3: 100% 352/352 [00:16<00:00, 21.66it/s, loss=0.7439, acc=50.22%]\n",
            "\n",
            "Training - Loss: 0.8083, Accuracy: 0.5022\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.5068\n",
            "Precision: 0.5036\n",
            "Recall:    0.9488\n",
            "F1 Score:  0.6580\n",
            "ROC-AUC:   0.5208\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "Epoch 4/10\n",
            "============================================================\n",
            "Epoch 4: 100% 352/352 [00:15<00:00, 22.01it/s, loss=0.7825, acc=50.20%]\n",
            "\n",
            "Training - Loss: 0.7606, Accuracy: 0.5020\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.4972\n",
            "Precision: 0.4979\n",
            "Recall:    0.6728\n",
            "F1 Score:  0.5723\n",
            "ROC-AUC:   0.5005\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "Epoch 5/10\n",
            "============================================================\n",
            "Epoch 5: 100% 352/352 [00:16<00:00, 21.20it/s, loss=0.6920, acc=49.80%]\n",
            "\n",
            "Training - Loss: 0.7310, Accuracy: 0.4980\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.4980\n",
            "Precision: 0.4980\n",
            "Recall:    0.4920\n",
            "F1 Score:  0.4950\n",
            "ROC-AUC:   0.4908\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "Epoch 6/10\n",
            "============================================================\n",
            "Epoch 6: 100% 352/352 [00:16<00:00, 21.98it/s, loss=0.7369, acc=50.60%]\n",
            "\n",
            "Training - Loss: 0.7104, Accuracy: 0.5060\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.5036\n",
            "Precision: 0.5049\n",
            "Recall:    0.3704\n",
            "F1 Score:  0.4273\n",
            "ROC-AUC:   0.4988\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "Epoch 7/10\n",
            "============================================================\n",
            "Epoch 7: 100% 352/352 [00:15<00:00, 22.00it/s, loss=0.7326, acc=49.80%]\n",
            "\n",
            "Training - Loss: 0.7030, Accuracy: 0.4980\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.5000\n",
            "Precision: 0.5000\n",
            "Recall:    0.9256\n",
            "F1 Score:  0.6493\n",
            "ROC-AUC:   0.4968\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "Epoch 8/10\n",
            "============================================================\n",
            "Epoch 8: 100% 352/352 [00:16<00:00, 21.54it/s, loss=0.7387, acc=50.51%]\n",
            "\n",
            "Training - Loss: 0.6973, Accuracy: 0.5051\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.4996\n",
            "Precision: 0.4998\n",
            "Recall:    0.9992\n",
            "F1 Score:  0.6663\n",
            "ROC-AUC:   0.5207\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/gru/gru_best.pt\n",
            "✓ Best model saved (F1: 0.6663)\n",
            "\n",
            "============================================================\n",
            "Epoch 9/10\n",
            "============================================================\n",
            "Epoch 9: 100% 352/352 [00:15<00:00, 22.09it/s, loss=0.6931, acc=50.21%]\n",
            "\n",
            "Training - Loss: 0.6966, Accuracy: 0.5021\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.5000\n",
            "Precision: 0.5000\n",
            "Recall:    1.0000\n",
            "F1 Score:  0.6667\n",
            "ROC-AUC:   0.5386\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/gru/gru_best.pt\n",
            "✓ Best model saved (F1: 0.6667)\n",
            "\n",
            "============================================================\n",
            "Epoch 10/10\n",
            "============================================================\n",
            "Epoch 10: 100% 352/352 [00:16<00:00, 21.28it/s, loss=0.6995, acc=50.33%]\n",
            "\n",
            "Training - Loss: 0.6952, Accuracy: 0.5033\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.5000\n",
            "Precision: 0.5000\n",
            "Recall:    1.0000\n",
            "F1 Score:  0.6667\n",
            "ROC-AUC:   0.5447\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "Training Complete!\n",
            "  Best epoch: 9\n",
            "  Best validation F1: 0.6667\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Evaluating best model on test set...\n",
            "============================================================\n",
            "\n",
            "Test Results:\n",
            "\n",
            "Test\n",
            "==================================================\n",
            "Accuracy:  0.5000\n",
            "Precision: 0.5000\n",
            "Recall:    0.9999\n",
            "F1 Score:  0.6666\n",
            "ROC-AUC:   0.5303\n",
            "==================================================\n",
            "\n",
            "✓ Training complete!\n",
            "\n",
            "Final Test Results:\n",
            "  Accuracy: 0.5000\n",
            "  Precision: 0.5000\n",
            "  Recall: 0.9999\n",
            "  F1 Score: 0.6666\n",
            "  ROC-AUC: 0.5303\n"
          ]
        }
      ],
      "source": [
        "# train GRU End-to-End\n",
        "\n",
        "!python src/training/train_end_to_end_dl.py \\\n",
        "    --dataset {dataset_arg} \\\n",
        "    --model gru \\\n",
        "    --epochs 10 \\\n",
        "    --batch_size 64 \\\n",
        "    --lr 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7240d7c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7240d7c3",
        "outputId": "d49fc583-d2b4-4904-b23c-5d83f941002a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded from configs/config.yaml\n",
            "Random seed set to 42\n",
            "Using GPU: Tesla T4\n",
            "Initialized EndToEndDLTrainer\n",
            "  Model type: transformer\n",
            "  Device: cuda\n",
            "\n",
            "============================================================\n",
            "Training on IMDB Dataset\n",
            "============================================================\n",
            "\n",
            "Loading dataset...\n",
            "Loaded dataset from cache: data/processed/imdb_cache.pkl\n",
            "\n",
            "Building vocabulary...\n",
            "Building vocabulary...\n",
            "Vocabulary size: 20000\n",
            "Most common words: ['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
            "\n",
            "Creating TRANSFORMER model...\n",
            "  ✓ Applied Xavier initialization to classifier\n",
            "  Total parameters: 8,088,806\n",
            "\n",
            "Preparing data loaders...\n",
            "  Train batches: 704\n",
            "  Val batches: 79\n",
            "  Test batches: 782\n",
            "\n",
            "============================================================\n",
            "Training TRANSFORMER Model\n",
            "============================================================\n",
            "  Epochs: 5\n",
            "  Learning rate: 0.0001\n",
            "  Batch size: 32\n",
            "\n",
            "============================================================\n",
            "Epoch 1/5\n",
            "============================================================\n",
            "Epoch 1: 100% 704/704 [00:51<00:00, 13.73it/s, loss=0.7524, acc=70.78%]\n",
            "\n",
            "Training - Loss: 0.5465, Accuracy: 0.7078\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
            "  output = torch._nested_tensor_from_mask(\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.7868\n",
            "Precision: 0.7884\n",
            "Recall:    0.7840\n",
            "F1 Score:  0.7862\n",
            "ROC-AUC:   0.8633\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/transformer/transformer_best.pt\n",
            "✓ Best model saved (F1: 0.7862)\n",
            "\n",
            "============================================================\n",
            "Epoch 2/5\n",
            "============================================================\n",
            "Epoch 2: 100% 704/704 [00:49<00:00, 14.15it/s, loss=0.3535, acc=79.46%]\n",
            "\n",
            "Training - Loss: 0.4419, Accuracy: 0.7946\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.8024\n",
            "Precision: 0.7926\n",
            "Recall:    0.8192\n",
            "F1 Score:  0.8057\n",
            "ROC-AUC:   0.8890\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/transformer/transformer_best.pt\n",
            "✓ Best model saved (F1: 0.8057)\n",
            "\n",
            "============================================================\n",
            "Epoch 3/5\n",
            "============================================================\n",
            "Epoch 3: 100% 704/704 [00:50<00:00, 14.00it/s, loss=0.2290, acc=81.76%]\n",
            "\n",
            "Training - Loss: 0.4018, Accuracy: 0.8176\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.8168\n",
            "Precision: 0.8084\n",
            "Recall:    0.8304\n",
            "F1 Score:  0.8193\n",
            "ROC-AUC:   0.9015\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/transformer/transformer_best.pt\n",
            "✓ Best model saved (F1: 0.8193)\n",
            "\n",
            "============================================================\n",
            "Epoch 4/5\n",
            "============================================================\n",
            "Epoch 4: 100% 704/704 [00:49<00:00, 14.10it/s, loss=0.1444, acc=83.05%]\n",
            "\n",
            "Training - Loss: 0.3764, Accuracy: 0.8305\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.8044\n",
            "Precision: 0.7431\n",
            "Recall:    0.9304\n",
            "F1 Score:  0.8263\n",
            "ROC-AUC:   0.9103\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/transformer/transformer_best.pt\n",
            "✓ Best model saved (F1: 0.8263)\n",
            "\n",
            "============================================================\n",
            "Epoch 5/5\n",
            "============================================================\n",
            "Epoch 5: 100% 704/704 [00:50<00:00, 14.04it/s, loss=0.1176, acc=84.38%]\n",
            "\n",
            "Training - Loss: 0.3562, Accuracy: 0.8438\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.8196\n",
            "Precision: 0.7676\n",
            "Recall:    0.9168\n",
            "F1 Score:  0.8356\n",
            "ROC-AUC:   0.9159\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/transformer/transformer_best.pt\n",
            "✓ Best model saved (F1: 0.8356)\n",
            "\n",
            "============================================================\n",
            "Training Complete!\n",
            "  Best epoch: 5\n",
            "  Best validation F1: 0.8356\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Evaluating best model on test set...\n",
            "============================================================\n",
            "\n",
            "Test Results:\n",
            "\n",
            "Test\n",
            "==================================================\n",
            "Accuracy:  0.8200\n",
            "Precision: 0.7728\n",
            "Recall:    0.9066\n",
            "F1 Score:  0.8344\n",
            "ROC-AUC:   0.9126\n",
            "==================================================\n",
            "\n",
            "✓ Training complete!\n",
            "\n",
            "Final Test Results:\n",
            "  Accuracy: 0.8200\n",
            "  Precision: 0.7728\n",
            "  Recall: 0.9066\n",
            "  F1 Score: 0.8344\n",
            "  ROC-AUC: 0.9126\n"
          ]
        }
      ],
      "source": [
        "# train Transformer\n",
        "\n",
        "!python src/training/train_end_to_end_dl.py \\\n",
        "    --dataset {dataset_arg} \\\n",
        "    --model transformer \\\n",
        "    --epochs 5 \\\n",
        "    --batch_size 32 \\\n",
        "    --lr 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa7602b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa7602b1",
        "outputId": "137ea65b-f881-4b7c-a6a9-686c4e990935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded from configs/config.yaml\n",
            "Random seed set to 42\n",
            "Using GPU: Tesla T4\n",
            "Initialized EndToEndDLTrainer\n",
            "  Model type: bert\n",
            "  Device: cuda\n",
            "\n",
            "============================================================\n",
            "Training on IMDB Dataset\n",
            "============================================================\n",
            "\n",
            "Loading dataset...\n",
            "Loaded dataset from cache: data/processed/imdb_cache.pkl\n",
            "\n",
            "Building vocabulary...\n",
            "Building vocabulary...\n",
            "Vocabulary size: 20000\n",
            "Most common words: ['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
            "\n",
            "Creating BERT model...\n",
            "config.json: 100% 570/570 [00:00<00:00, 3.38MB/s]\n",
            "2025-12-01 14:17:52.415341: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764598672.437897    6792 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764598672.444652    6792 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764598672.463190    6792 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764598672.463229    6792 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764598672.463234    6792 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764598672.463240    6792 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-01 14:17:52.468666: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors: 100% 440M/440M [00:02<00:00, 202MB/s]\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 327kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 8.30MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 18.6MB/s]\n",
            "  Total parameters: 109,483,778\n",
            "\n",
            "Preparing data loaders...\n",
            "  Train batches: 1407\n",
            "  Val batches: 157\n",
            "  Test batches: 1563\n",
            "\n",
            "============================================================\n",
            "Training BERT Model\n",
            "============================================================\n",
            "  Epochs: 3\n",
            "  Learning rate: 2e-05\n",
            "  Batch size: 16\n",
            "\n",
            "============================================================\n",
            "Epoch 1/3\n",
            "============================================================\n",
            "Epoch 1: 100% 1407/1407 [35:51<00:00,  1.53s/it, loss=0.0052, acc=90.14%]\n",
            "\n",
            "Training - Loss: 0.2540, Accuracy: 0.9014\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.9148\n",
            "Precision: 0.8913\n",
            "Recall:    0.9448\n",
            "F1 Score:  0.9173\n",
            "ROC-AUC:   0.9757\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/bert/bert_best.pt\n",
            "✓ Best model saved (F1: 0.9173)\n",
            "\n",
            "============================================================\n",
            "Epoch 2/3\n",
            "============================================================\n",
            "Epoch 2: 100% 1407/1407 [35:51<00:00,  1.53s/it, loss=0.0061, acc=95.59%]\n",
            "\n",
            "Training - Loss: 0.1444, Accuracy: 0.9559\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.9304\n",
            "Precision: 0.9424\n",
            "Recall:    0.9168\n",
            "F1 Score:  0.9294\n",
            "ROC-AUC:   0.9790\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/bert/bert_best.pt\n",
            "✓ Best model saved (F1: 0.9294)\n",
            "\n",
            "============================================================\n",
            "Epoch 3/3\n",
            "============================================================\n",
            "Epoch 3: 100% 1407/1407 [35:50<00:00,  1.53s/it, loss=0.0033, acc=97.73%]\n",
            "\n",
            "Training - Loss: 0.0879, Accuracy: 0.9773\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.9288\n",
            "Precision: 0.9288\n",
            "Recall:    0.9288\n",
            "F1 Score:  0.9288\n",
            "ROC-AUC:   0.9779\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "Training Complete!\n",
            "  Best epoch: 2\n",
            "  Best validation F1: 0.9294\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Evaluating best model on test set...\n",
            "============================================================\n",
            "\n",
            "Test Results:\n",
            "\n",
            "Test\n",
            "==================================================\n",
            "Accuracy:  0.9368\n",
            "Precision: 0.9403\n",
            "Recall:    0.9329\n",
            "F1 Score:  0.9366\n",
            "ROC-AUC:   0.9831\n",
            "==================================================\n",
            "\n",
            "✓ Training complete!\n",
            "\n",
            "Final Test Results:\n",
            "  Accuracy: 0.9368\n",
            "  Precision: 0.9403\n",
            "  Recall: 0.9329\n",
            "  F1 Score: 0.9366\n",
            "  ROC-AUC: 0.9831\n",
            "BERT model trained on IMDB dataset\n"
          ]
        }
      ],
      "source": [
        "!python src/training/train_end_to_end_dl.py \\\n",
        "    --dataset {dataset_arg} \\\n",
        "    --model bert \\\n",
        "    --epochs 3 \\\n",
        "    --batch_size 16 \\\n",
        "    --lr 2e-5\n",
        "\n",
        "print(f\"BERT model trained on {dataset_arg.upper()} dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3896d89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3896d89",
        "outputId": "f5255768-10fe-4805-8381-d1851433acca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded from configs/config.yaml\n",
            "Random seed set to 42\n",
            "Using GPU: Tesla T4\n",
            "Initialized EndToEndDLTrainer\n",
            "  Model type: roberta\n",
            "  Device: cuda\n",
            "\n",
            "============================================================\n",
            "Training on IMDB Dataset\n",
            "============================================================\n",
            "\n",
            "Loading dataset...\n",
            "Loading IMDb dataset...\n",
            "Saved dataset to cache: data/processed/imdb_cache.pkl\n",
            "Train size: 22500, Val size: 2500, Test size: 25000\n",
            "\n",
            "Building vocabulary...\n",
            "Building vocabulary...\n",
            "Vocabulary size: 20000\n",
            "Most common words: ['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
            "\n",
            "Creating ROBERTA model...\n",
            "config.json: 100% 481/481 [00:00<00:00, 3.44MB/s]\n",
            "2025-12-02 12:29:10.095889: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764678550.117952    1158 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764678550.124693    1158 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764678550.141287    1158 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764678550.141316    1158 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764678550.141320    1158 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764678550.141326    1158 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 12:29:10.146125: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors: 100% 499M/499M [00:02<00:00, 204MB/s]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 180kB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 18.6MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 16.0MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 34.8MB/s]\n",
            "  Total parameters: 124,647,170\n",
            "\n",
            "Preparing data loaders...\n",
            "  Train batches: 1407\n",
            "  Val batches: 157\n",
            "  Test batches: 1563\n",
            "\n",
            "============================================================\n",
            "Training ROBERTA Model\n",
            "============================================================\n",
            "  Epochs: 3\n",
            "  Learning rate: 2e-05\n",
            "  Batch size: 16\n",
            "\n",
            "============================================================\n",
            "Epoch 1/3\n",
            "============================================================\n",
            "Epoch 1: 100% 1407/1407 [35:12<00:00,  1.50s/it, loss=0.0036, acc=90.80%]\n",
            "\n",
            "Training - Loss: 0.2609, Accuracy: 0.9080\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.9348\n",
            "Precision: 0.9243\n",
            "Recall:    0.9472\n",
            "F1 Score:  0.9356\n",
            "ROC-AUC:   0.9836\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/roberta/roberta_best.pt\n",
            "✓ Best model saved (F1: 0.9356)\n",
            "\n",
            "============================================================\n",
            "Epoch 2/3\n",
            "============================================================\n",
            "Epoch 2: 100% 1407/1407 [35:17<00:00,  1.50s/it, loss=0.0064, acc=95.73%]\n",
            "\n",
            "Training - Loss: 0.1575, Accuracy: 0.9573\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.9372\n",
            "Precision: 0.9266\n",
            "Recall:    0.9496\n",
            "F1 Score:  0.9380\n",
            "ROC-AUC:   0.9840\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/roberta/roberta_best.pt\n",
            "✓ Best model saved (F1: 0.9380)\n",
            "\n",
            "============================================================\n",
            "Epoch 3/3\n",
            "============================================================\n",
            "Epoch 3: 100% 1407/1407 [35:15<00:00,  1.50s/it, loss=1.4427, acc=97.61%]\n",
            "\n",
            "Training - Loss: 0.1047, Accuracy: 0.9761\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.9424\n",
            "Precision: 0.9403\n",
            "Recall:    0.9448\n",
            "F1 Score:  0.9425\n",
            "ROC-AUC:   0.9830\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/roberta/roberta_best.pt\n",
            "✓ Best model saved (F1: 0.9425)\n",
            "\n",
            "============================================================\n",
            "Training Complete!\n",
            "  Best epoch: 3\n",
            "  Best validation F1: 0.9425\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Evaluating best model on test set...\n",
            "============================================================\n",
            "\n",
            "Test Results:\n",
            "\n",
            "Test\n",
            "==================================================\n",
            "Accuracy:  0.9455\n",
            "Precision: 0.9318\n",
            "Recall:    0.9614\n",
            "F1 Score:  0.9463\n",
            "ROC-AUC:   0.9866\n",
            "==================================================\n",
            "\n",
            "✓ Training complete!\n",
            "\n",
            "Final Test Results:\n",
            "  Accuracy: 0.9455\n",
            "  Precision: 0.9318\n",
            "  Recall: 0.9614\n",
            "  F1 Score: 0.9463\n",
            "  ROC-AUC: 0.9866\n",
            "RoBERTa model trained on IMDB dataset\n"
          ]
        }
      ],
      "source": [
        "!python src/training/train_end_to_end_dl.py \\\n",
        "    --dataset {dataset_arg} \\\n",
        "    --model roberta \\\n",
        "    --epochs 3 \\\n",
        "    --batch_size 16 \\\n",
        "    --lr 2e-5\n",
        "\n",
        "print(f\"RoBERTa model trained on {dataset_arg.upper()} dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b34c3dba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b34c3dba",
        "outputId": "5c347c05-28f3-408b-8dce-dd57c225241a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded from configs/config.yaml\n",
            "Random seed set to 42\n",
            "Using GPU: Tesla T4\n",
            "Initialized EndToEndDLTrainer\n",
            "  Model type: distilbert\n",
            "  Device: cuda\n",
            "\n",
            "============================================================\n",
            "Training on IMDB Dataset\n",
            "============================================================\n",
            "\n",
            "Loading dataset...\n",
            "Loaded dataset from cache: data/processed/imdb_cache.pkl\n",
            "\n",
            "Building vocabulary...\n",
            "Building vocabulary...\n",
            "Vocabulary size: 20000\n",
            "Most common words: ['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
            "\n",
            "Creating DISTILBERT model...\n",
            "config.json: 100% 483/483 [00:00<00:00, 2.50MB/s]\n",
            "2025-12-02 14:33:11.823080: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764685991.846203   32020 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764685991.853232   32020 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764685991.870916   32020 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764685991.870958   32020 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764685991.870963   32020 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764685991.870968   32020 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 14:33:11.876487: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors: 100% 268M/268M [00:03<00:00, 78.8MB/s]\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 331kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 7.18MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 25.1MB/s]\n",
            "  Total parameters: 66,364,418\n",
            "\n",
            "Preparing data loaders...\n",
            "  Train batches: 1407\n",
            "  Val batches: 157\n",
            "  Test batches: 1563\n",
            "\n",
            "============================================================\n",
            "Training DISTILBERT Model\n",
            "============================================================\n",
            "  Epochs: 3\n",
            "  Learning rate: 2e-05\n",
            "  Batch size: 16\n",
            "\n",
            "============================================================\n",
            "Epoch 1/3\n",
            "============================================================\n",
            "Epoch 1: 100% 1407/1407 [17:35<00:00,  1.33it/s, loss=0.0264, acc=89.16%]\n",
            "\n",
            "Training - Loss: 0.2690, Accuracy: 0.8916\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.9140\n",
            "Precision: 0.8953\n",
            "Recall:    0.9376\n",
            "F1 Score:  0.9160\n",
            "ROC-AUC:   0.9733\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/distilbert/distilbert_best.pt\n",
            "✓ Best model saved (F1: 0.9160)\n",
            "\n",
            "============================================================\n",
            "Epoch 2/3\n",
            "============================================================\n",
            "Epoch 2: 100% 1407/1407 [17:36<00:00,  1.33it/s, loss=0.0109, acc=94.55%]\n",
            "\n",
            "Training - Loss: 0.1651, Accuracy: 0.9455\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.9168\n",
            "Precision: 0.9122\n",
            "Recall:    0.9224\n",
            "F1 Score:  0.9173\n",
            "ROC-AUC:   0.9739\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/distilbert/distilbert_best.pt\n",
            "✓ Best model saved (F1: 0.9173)\n",
            "\n",
            "============================================================\n",
            "Epoch 3/3\n",
            "============================================================\n",
            "Epoch 3: 100% 1407/1407 [17:36<00:00,  1.33it/s, loss=0.0040, acc=97.38%]\n",
            "\n",
            "Training - Loss: 0.0991, Accuracy: 0.9738\n",
            "\n",
            "Validation Results:\n",
            "\n",
            "Validation\n",
            "==================================================\n",
            "Accuracy:  0.9244\n",
            "Precision: 0.9282\n",
            "Recall:    0.9200\n",
            "F1 Score:  0.9241\n",
            "ROC-AUC:   0.9753\n",
            "==================================================\n",
            "Checkpoint saved to results/models/deep_learning/imdb/distilbert/distilbert_best.pt\n",
            "✓ Best model saved (F1: 0.9241)\n",
            "\n",
            "============================================================\n",
            "Training Complete!\n",
            "  Best epoch: 3\n",
            "  Best validation F1: 0.9241\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Evaluating best model on test set...\n",
            "============================================================\n",
            "\n",
            "Test Results:\n",
            "\n",
            "Test\n",
            "==================================================\n",
            "Accuracy:  0.9256\n",
            "Precision: 0.9268\n",
            "Recall:    0.9241\n",
            "F1 Score:  0.9254\n",
            "ROC-AUC:   0.9759\n",
            "==================================================\n",
            "\n",
            "✓ Training complete!\n",
            "\n",
            "Final Test Results:\n",
            "  Accuracy: 0.9256\n",
            "  Precision: 0.9268\n",
            "  Recall: 0.9241\n",
            "  F1 Score: 0.9254\n",
            "  ROC-AUC: 0.9759\n",
            "DistilBERT model trained on IMDB dataset\n"
          ]
        }
      ],
      "source": [
        "!python src/training/train_end_to_end_dl.py \\\n",
        "    --dataset {dataset_arg} \\\n",
        "    --model distilbert \\\n",
        "    --epochs 3 \\\n",
        "    --batch_size 16 \\\n",
        "    --lr 2e-5\n",
        "\n",
        "print(f\"DistilBERT model trained on {dataset_arg.upper()} dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af5ced9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af5ced9f",
        "outputId": "0650a179-e366-46fc-b7a8-de461e396e29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set to 42\n",
            "Initialized ClassicalMLTrainer\n",
            "  Encoder type: lstm\n",
            "  Device: cuda\n",
            "\n",
            "============================================================\n",
            "Training Classical ML Models on IMDB\n",
            "============================================================\n",
            "\n",
            "Loading dataset...\n",
            "Loaded dataset from cache: data/processed/imdb_cache.pkl\n",
            "\n",
            "Building vocabulary...\n",
            "Building vocabulary...\n",
            "Vocabulary size: 20000\n",
            "Most common words: ['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
            "\n",
            "Loading lstm encoder...\n",
            "  No pre-trained encoder found, using random initialization\n",
            "✓ Random encoder initialized\n",
            "\n",
            "Extracting embeddings for 22500 samples...\n",
            "  Processed 320/22500 samples\n",
            "  Processed 640/22500 samples\n",
            "  Processed 960/22500 samples\n",
            "  Processed 1280/22500 samples\n",
            "  Processed 1600/22500 samples\n",
            "  Processed 1920/22500 samples\n",
            "  Processed 2240/22500 samples\n",
            "  Processed 2560/22500 samples\n",
            "  Processed 2880/22500 samples\n",
            "  Processed 3200/22500 samples\n",
            "  Processed 3520/22500 samples\n",
            "  Processed 3840/22500 samples\n",
            "  Processed 4160/22500 samples\n",
            "  Processed 4480/22500 samples\n",
            "  Processed 4800/22500 samples\n",
            "  Processed 5120/22500 samples\n",
            "  Processed 5440/22500 samples\n",
            "  Processed 5760/22500 samples\n",
            "  Processed 6080/22500 samples\n",
            "  Processed 6400/22500 samples\n",
            "  Processed 6720/22500 samples\n",
            "  Processed 7040/22500 samples\n",
            "  Processed 7360/22500 samples\n",
            "  Processed 7680/22500 samples\n",
            "  Processed 8000/22500 samples\n",
            "  Processed 8320/22500 samples\n",
            "  Processed 8640/22500 samples\n",
            "  Processed 8960/22500 samples\n",
            "  Processed 9280/22500 samples\n",
            "  Processed 9600/22500 samples\n",
            "  Processed 9920/22500 samples\n",
            "  Processed 10240/22500 samples\n",
            "  Processed 10560/22500 samples\n",
            "  Processed 10880/22500 samples\n",
            "  Processed 11200/22500 samples\n",
            "  Processed 11520/22500 samples\n",
            "  Processed 11840/22500 samples\n",
            "  Processed 12160/22500 samples\n",
            "  Processed 12480/22500 samples\n",
            "  Processed 12800/22500 samples\n",
            "  Processed 13120/22500 samples\n",
            "  Processed 13440/22500 samples\n",
            "  Processed 13760/22500 samples\n",
            "  Processed 14080/22500 samples\n",
            "  Processed 14400/22500 samples\n",
            "  Processed 14720/22500 samples\n",
            "  Processed 15040/22500 samples\n",
            "  Processed 15360/22500 samples\n",
            "  Processed 15680/22500 samples\n",
            "  Processed 16000/22500 samples\n",
            "  Processed 16320/22500 samples\n",
            "  Processed 16640/22500 samples\n",
            "  Processed 16960/22500 samples\n",
            "  Processed 17280/22500 samples\n",
            "  Processed 17600/22500 samples\n",
            "  Processed 17920/22500 samples\n",
            "  Processed 18240/22500 samples\n",
            "  Processed 18560/22500 samples\n",
            "  Processed 18880/22500 samples\n",
            "  Processed 19200/22500 samples\n",
            "  Processed 19520/22500 samples\n",
            "  Processed 19840/22500 samples\n",
            "  Processed 20160/22500 samples\n",
            "  Processed 20480/22500 samples\n",
            "  Processed 20800/22500 samples\n",
            "  Processed 21120/22500 samples\n",
            "  Processed 21440/22500 samples\n",
            "  Processed 21760/22500 samples\n",
            "  Processed 22080/22500 samples\n",
            "  Processed 22400/22500 samples\n",
            "✓ Embeddings extracted: (22500, 256)\n",
            "\n",
            "Extracting embeddings for 2500 samples...\n",
            "  Processed 320/2500 samples\n",
            "  Processed 640/2500 samples\n",
            "  Processed 960/2500 samples\n",
            "  Processed 1280/2500 samples\n",
            "  Processed 1600/2500 samples\n",
            "  Processed 1920/2500 samples\n",
            "  Processed 2240/2500 samples\n",
            "✓ Embeddings extracted: (2500, 256)\n",
            "\n",
            "Extracting embeddings for 25000 samples...\n",
            "  Processed 320/25000 samples\n",
            "  Processed 640/25000 samples\n",
            "  Processed 960/25000 samples\n",
            "  Processed 1280/25000 samples\n",
            "  Processed 1600/25000 samples\n",
            "  Processed 1920/25000 samples\n",
            "  Processed 2240/25000 samples\n",
            "  Processed 2560/25000 samples\n",
            "  Processed 2880/25000 samples\n",
            "  Processed 3200/25000 samples\n",
            "  Processed 3520/25000 samples\n",
            "  Processed 3840/25000 samples\n",
            "  Processed 4160/25000 samples\n",
            "  Processed 4480/25000 samples\n",
            "  Processed 4800/25000 samples\n",
            "  Processed 5120/25000 samples\n",
            "  Processed 5440/25000 samples\n",
            "  Processed 5760/25000 samples\n",
            "  Processed 6080/25000 samples\n",
            "  Processed 6400/25000 samples\n",
            "  Processed 6720/25000 samples\n",
            "  Processed 7040/25000 samples\n",
            "  Processed 7360/25000 samples\n",
            "  Processed 7680/25000 samples\n",
            "  Processed 8000/25000 samples\n",
            "  Processed 8320/25000 samples\n",
            "  Processed 8640/25000 samples\n",
            "  Processed 8960/25000 samples\n",
            "  Processed 9280/25000 samples\n",
            "  Processed 9600/25000 samples\n",
            "  Processed 9920/25000 samples\n",
            "  Processed 10240/25000 samples\n",
            "  Processed 10560/25000 samples\n",
            "  Processed 10880/25000 samples\n",
            "  Processed 11200/25000 samples\n",
            "  Processed 11520/25000 samples\n",
            "  Processed 11840/25000 samples\n",
            "  Processed 12160/25000 samples\n",
            "  Processed 12480/25000 samples\n",
            "  Processed 12800/25000 samples\n",
            "  Processed 13120/25000 samples\n",
            "  Processed 13440/25000 samples\n",
            "  Processed 13760/25000 samples\n",
            "  Processed 14080/25000 samples\n",
            "  Processed 14400/25000 samples\n",
            "  Processed 14720/25000 samples\n",
            "  Processed 15040/25000 samples\n",
            "  Processed 15360/25000 samples\n",
            "  Processed 15680/25000 samples\n",
            "  Processed 16000/25000 samples\n",
            "  Processed 16320/25000 samples\n",
            "  Processed 16640/25000 samples\n",
            "  Processed 16960/25000 samples\n",
            "  Processed 17280/25000 samples\n",
            "  Processed 17600/25000 samples\n",
            "  Processed 17920/25000 samples\n",
            "  Processed 18240/25000 samples\n",
            "  Processed 18560/25000 samples\n",
            "  Processed 18880/25000 samples\n",
            "  Processed 19200/25000 samples\n",
            "  Processed 19520/25000 samples\n",
            "  Processed 19840/25000 samples\n",
            "  Processed 20160/25000 samples\n",
            "  Processed 20480/25000 samples\n",
            "  Processed 20800/25000 samples\n",
            "  Processed 21120/25000 samples\n",
            "  Processed 21440/25000 samples\n",
            "  Processed 21760/25000 samples\n",
            "  Processed 22080/25000 samples\n",
            "  Processed 22400/25000 samples\n",
            "  Processed 22720/25000 samples\n",
            "  Processed 23040/25000 samples\n",
            "  Processed 23360/25000 samples\n",
            "  Processed 23680/25000 samples\n",
            "  Processed 24000/25000 samples\n",
            "  Processed 24320/25000 samples\n",
            "  Processed 24640/25000 samples\n",
            "  Processed 24960/25000 samples\n",
            "✓ Embeddings extracted: (25000, 256)\n",
            "\n",
            "============================================================\n",
            "Training LOGISTIC_REGRESSION\n",
            "============================================================\n",
            "Training Logistic Regression...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 256\n",
            "  C (regularization): 0.01\n",
            "  Penalty: l1\n",
            "  Solver: liblinear\n",
            "  Normalize: True\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.5802\n",
            "  Validation accuracy: 0.5716\n",
            "  Iterations: 11\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.5665\n",
            "  Precision: 0.5662\n",
            "  Recall:    0.5682\n",
            "  F1 Score:  0.5672\n",
            "  ROC-AUC:   0.5939\n",
            "Model saved to results/models/classical_ml/imdb/lstm/logistic_regression.pkl\n",
            "\n",
            "============================================================\n",
            "Training RANDOM_FOREST\n",
            "============================================================\n",
            "Training Random Forest...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 256\n",
            "  Number of trees: 100\n",
            "  Max depth: 10\n",
            "  Max features: sqrt\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.9531\n",
            "  Validation accuracy: 0.5812\n",
            "  Number of trees: 100\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.5727\n",
            "  Precision: 0.5747\n",
            "  Recall:    0.5596\n",
            "  F1 Score:  0.5670\n",
            "  ROC-AUC:   0.6101\n",
            "Model saved to results/models/classical_ml/imdb/lstm/random_forest.pkl\n",
            "\n",
            "============================================================\n",
            "Training XGBOOST\n",
            "============================================================\n",
            "Training XGBoost...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 256\n",
            "  Number of estimators: 100\n",
            "  Max depth: 3\n",
            "  Learning rate: 0.01\n",
            "  Subsample: 0.8\n",
            "  Colsample by tree: 0.8\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [16:30:51] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.5915\n",
            "  Validation accuracy: 0.5568\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.5517\n",
            "  Precision: 0.5513\n",
            "  Recall:    0.5553\n",
            "  F1 Score:  0.5533\n",
            "  ROC-AUC:   0.5748\n",
            "Model saved to results/models/classical_ml/imdb/lstm/xgboost.pkl\n",
            "\n",
            "✓ Results saved to results/classical_ml/imdb/lstm/results_20251201_163054.pkl\n",
            "\n",
            "============================================================\n",
            "RESULTS SUMMARY\n",
            "============================================================\n",
            "Model                Train Acc    Val Acc      Test Acc     Test F1     \n",
            "------------------------------------------------------------\n",
            "logistic_regression  0.5802       0.5716       0.5665       0.5672      \n",
            "random_forest        0.9531       0.5812       0.5727       0.5670      \n",
            "xgboost              0.5915       0.5568       0.5517       0.5533      \n",
            "\n",
            "✓ Training complete!\n"
          ]
        }
      ],
      "source": [
        "# train hybrid models (LSTM + Classical ML)\n",
        "\n",
        "!python src/training/train_classical_ml.py \\\n",
        "    --dataset {dataset_arg} \\\n",
        "    --encoder lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "940c8886",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "940c8886",
        "outputId": "a85697f9-b605-41e6-819b-e923d77694b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set to 42\n",
            "Initialized ClassicalMLTrainer\n",
            "  Encoder type: gru\n",
            "  Device: cuda\n",
            "\n",
            "============================================================\n",
            "Training Classical ML Models on IMDB\n",
            "============================================================\n",
            "\n",
            "Loading dataset...\n",
            "Loaded dataset from cache: data/processed/imdb_cache.pkl\n",
            "\n",
            "Building vocabulary...\n",
            "Building vocabulary...\n",
            "Vocabulary size: 20000\n",
            "Most common words: ['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
            "\n",
            "Loading gru encoder...\n",
            "  No pre-trained encoder found, using random initialization\n",
            "✓ Random encoder initialized\n",
            "\n",
            "Extracting embeddings for 22500 samples...\n",
            "  Processed 320/22500 samples\n",
            "  Processed 640/22500 samples\n",
            "  Processed 960/22500 samples\n",
            "  Processed 1280/22500 samples\n",
            "  Processed 1600/22500 samples\n",
            "  Processed 1920/22500 samples\n",
            "  Processed 2240/22500 samples\n",
            "  Processed 2560/22500 samples\n",
            "  Processed 2880/22500 samples\n",
            "  Processed 3200/22500 samples\n",
            "  Processed 3520/22500 samples\n",
            "  Processed 3840/22500 samples\n",
            "  Processed 4160/22500 samples\n",
            "  Processed 4480/22500 samples\n",
            "  Processed 4800/22500 samples\n",
            "  Processed 5120/22500 samples\n",
            "  Processed 5440/22500 samples\n",
            "  Processed 5760/22500 samples\n",
            "  Processed 6080/22500 samples\n",
            "  Processed 6400/22500 samples\n",
            "  Processed 6720/22500 samples\n",
            "  Processed 7040/22500 samples\n",
            "  Processed 7360/22500 samples\n",
            "  Processed 7680/22500 samples\n",
            "  Processed 8000/22500 samples\n",
            "  Processed 8320/22500 samples\n",
            "  Processed 8640/22500 samples\n",
            "  Processed 8960/22500 samples\n",
            "  Processed 9280/22500 samples\n",
            "  Processed 9600/22500 samples\n",
            "  Processed 9920/22500 samples\n",
            "  Processed 10240/22500 samples\n",
            "  Processed 10560/22500 samples\n",
            "  Processed 10880/22500 samples\n",
            "  Processed 11200/22500 samples\n",
            "  Processed 11520/22500 samples\n",
            "  Processed 11840/22500 samples\n",
            "  Processed 12160/22500 samples\n",
            "  Processed 12480/22500 samples\n",
            "  Processed 12800/22500 samples\n",
            "  Processed 13120/22500 samples\n",
            "  Processed 13440/22500 samples\n",
            "  Processed 13760/22500 samples\n",
            "  Processed 14080/22500 samples\n",
            "  Processed 14400/22500 samples\n",
            "  Processed 14720/22500 samples\n",
            "  Processed 15040/22500 samples\n",
            "  Processed 15360/22500 samples\n",
            "  Processed 15680/22500 samples\n",
            "  Processed 16000/22500 samples\n",
            "  Processed 16320/22500 samples\n",
            "  Processed 16640/22500 samples\n",
            "  Processed 16960/22500 samples\n",
            "  Processed 17280/22500 samples\n",
            "  Processed 17600/22500 samples\n",
            "  Processed 17920/22500 samples\n",
            "  Processed 18240/22500 samples\n",
            "  Processed 18560/22500 samples\n",
            "  Processed 18880/22500 samples\n",
            "  Processed 19200/22500 samples\n",
            "  Processed 19520/22500 samples\n",
            "  Processed 19840/22500 samples\n",
            "  Processed 20160/22500 samples\n",
            "  Processed 20480/22500 samples\n",
            "  Processed 20800/22500 samples\n",
            "  Processed 21120/22500 samples\n",
            "  Processed 21440/22500 samples\n",
            "  Processed 21760/22500 samples\n",
            "  Processed 22080/22500 samples\n",
            "  Processed 22400/22500 samples\n",
            "✓ Embeddings extracted: (22500, 256)\n",
            "\n",
            "Extracting embeddings for 2500 samples...\n",
            "  Processed 320/2500 samples\n",
            "  Processed 640/2500 samples\n",
            "  Processed 960/2500 samples\n",
            "  Processed 1280/2500 samples\n",
            "  Processed 1600/2500 samples\n",
            "  Processed 1920/2500 samples\n",
            "  Processed 2240/2500 samples\n",
            "✓ Embeddings extracted: (2500, 256)\n",
            "\n",
            "Extracting embeddings for 25000 samples...\n",
            "  Processed 320/25000 samples\n",
            "  Processed 640/25000 samples\n",
            "  Processed 960/25000 samples\n",
            "  Processed 1280/25000 samples\n",
            "  Processed 1600/25000 samples\n",
            "  Processed 1920/25000 samples\n",
            "  Processed 2240/25000 samples\n",
            "  Processed 2560/25000 samples\n",
            "  Processed 2880/25000 samples\n",
            "  Processed 3200/25000 samples\n",
            "  Processed 3520/25000 samples\n",
            "  Processed 3840/25000 samples\n",
            "  Processed 4160/25000 samples\n",
            "  Processed 4480/25000 samples\n",
            "  Processed 4800/25000 samples\n",
            "  Processed 5120/25000 samples\n",
            "  Processed 5440/25000 samples\n",
            "  Processed 5760/25000 samples\n",
            "  Processed 6080/25000 samples\n",
            "  Processed 6400/25000 samples\n",
            "  Processed 6720/25000 samples\n",
            "  Processed 7040/25000 samples\n",
            "  Processed 7360/25000 samples\n",
            "  Processed 7680/25000 samples\n",
            "  Processed 8000/25000 samples\n",
            "  Processed 8320/25000 samples\n",
            "  Processed 8640/25000 samples\n",
            "  Processed 8960/25000 samples\n",
            "  Processed 9280/25000 samples\n",
            "  Processed 9600/25000 samples\n",
            "  Processed 9920/25000 samples\n",
            "  Processed 10240/25000 samples\n",
            "  Processed 10560/25000 samples\n",
            "  Processed 10880/25000 samples\n",
            "  Processed 11200/25000 samples\n",
            "  Processed 11520/25000 samples\n",
            "  Processed 11840/25000 samples\n",
            "  Processed 12160/25000 samples\n",
            "  Processed 12480/25000 samples\n",
            "  Processed 12800/25000 samples\n",
            "  Processed 13120/25000 samples\n",
            "  Processed 13440/25000 samples\n",
            "  Processed 13760/25000 samples\n",
            "  Processed 14080/25000 samples\n",
            "  Processed 14400/25000 samples\n",
            "  Processed 14720/25000 samples\n",
            "  Processed 15040/25000 samples\n",
            "  Processed 15360/25000 samples\n",
            "  Processed 15680/25000 samples\n",
            "  Processed 16000/25000 samples\n",
            "  Processed 16320/25000 samples\n",
            "  Processed 16640/25000 samples\n",
            "  Processed 16960/25000 samples\n",
            "  Processed 17280/25000 samples\n",
            "  Processed 17600/25000 samples\n",
            "  Processed 17920/25000 samples\n",
            "  Processed 18240/25000 samples\n",
            "  Processed 18560/25000 samples\n",
            "  Processed 18880/25000 samples\n",
            "  Processed 19200/25000 samples\n",
            "  Processed 19520/25000 samples\n",
            "  Processed 19840/25000 samples\n",
            "  Processed 20160/25000 samples\n",
            "  Processed 20480/25000 samples\n",
            "  Processed 20800/25000 samples\n",
            "  Processed 21120/25000 samples\n",
            "  Processed 21440/25000 samples\n",
            "  Processed 21760/25000 samples\n",
            "  Processed 22080/25000 samples\n",
            "  Processed 22400/25000 samples\n",
            "  Processed 22720/25000 samples\n",
            "  Processed 23040/25000 samples\n",
            "  Processed 23360/25000 samples\n",
            "  Processed 23680/25000 samples\n",
            "  Processed 24000/25000 samples\n",
            "  Processed 24320/25000 samples\n",
            "  Processed 24640/25000 samples\n",
            "  Processed 24960/25000 samples\n",
            "✓ Embeddings extracted: (25000, 256)\n",
            "\n",
            "============================================================\n",
            "Training LOGISTIC_REGRESSION\n",
            "============================================================\n",
            "Training Logistic Regression...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 256\n",
            "  C (regularization): 0.01\n",
            "  Penalty: l1\n",
            "  Solver: liblinear\n",
            "  Normalize: True\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.5888\n",
            "  Validation accuracy: 0.5788\n",
            "  Iterations: 12\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.5772\n",
            "  Precision: 0.5780\n",
            "  Recall:    0.5715\n",
            "  F1 Score:  0.5748\n",
            "  ROC-AUC:   0.6086\n",
            "Model saved to results/models/classical_ml/imdb/gru/logistic_regression.pkl\n",
            "\n",
            "============================================================\n",
            "Training RANDOM_FOREST\n",
            "============================================================\n",
            "Training Random Forest...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 256\n",
            "  Number of trees: 100\n",
            "  Max depth: 10\n",
            "  Max features: sqrt\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.9600\n",
            "  Validation accuracy: 0.5924\n",
            "  Number of trees: 100\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.5864\n",
            "  Precision: 0.5890\n",
            "  Recall:    0.5717\n",
            "  F1 Score:  0.5802\n",
            "  ROC-AUC:   0.6256\n",
            "Model saved to results/models/classical_ml/imdb/gru/random_forest.pkl\n",
            "\n",
            "============================================================\n",
            "Training XGBOOST\n",
            "============================================================\n",
            "Training XGBoost...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 256\n",
            "  Number of estimators: 100\n",
            "  Max depth: 3\n",
            "  Learning rate: 0.01\n",
            "  Subsample: 0.8\n",
            "  Colsample by tree: 0.8\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [16:33:26] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.6057\n",
            "  Validation accuracy: 0.5676\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.5661\n",
            "  Precision: 0.5673\n",
            "  Recall:    0.5569\n",
            "  F1 Score:  0.5621\n",
            "  ROC-AUC:   0.5955\n",
            "Model saved to results/models/classical_ml/imdb/gru/xgboost.pkl\n",
            "\n",
            "✓ Results saved to results/classical_ml/imdb/gru/results_20251201_163329.pkl\n",
            "\n",
            "============================================================\n",
            "RESULTS SUMMARY\n",
            "============================================================\n",
            "Model                Train Acc    Val Acc      Test Acc     Test F1     \n",
            "------------------------------------------------------------\n",
            "logistic_regression  0.5888       0.5788       0.5772       0.5748      \n",
            "random_forest        0.9600       0.5924       0.5864       0.5802      \n",
            "xgboost              0.6057       0.5676       0.5661       0.5621      \n",
            "\n",
            "✓ Training complete!\n"
          ]
        }
      ],
      "source": [
        "# train hybrid models (GRU + Classical ML)\n",
        "\n",
        "!python src/training/train_classical_ml.py \\\n",
        "    --dataset {dataset_arg} \\\n",
        "    --encoder gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7829c400",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7829c400",
        "outputId": "b5432029-be17-4960-cf3b-a049718ea949"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set to 42\n",
            "Initialized ClassicalMLTrainer\n",
            "  Encoder type: transformer\n",
            "  Device: cuda\n",
            "\n",
            "============================================================\n",
            "Training Classical ML Models on IMDB\n",
            "============================================================\n",
            "\n",
            "Loading dataset...\n",
            "Loaded dataset from cache: data/processed/imdb_cache.pkl\n",
            "\n",
            "Building vocabulary...\n",
            "Building vocabulary...\n",
            "Vocabulary size: 20000\n",
            "Most common words: ['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
            "\n",
            "Loading transformer encoder...\n",
            "  No pre-trained encoder found, using random initialization\n",
            "✓ Random encoder initialized\n",
            "\n",
            "Extracting embeddings for 22500 samples...\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
            "  output = torch._nested_tensor_from_mask(\n",
            "  Processed 320/22500 samples\n",
            "  Processed 640/22500 samples\n",
            "  Processed 960/22500 samples\n",
            "  Processed 1280/22500 samples\n",
            "  Processed 1600/22500 samples\n",
            "  Processed 1920/22500 samples\n",
            "  Processed 2240/22500 samples\n",
            "  Processed 2560/22500 samples\n",
            "  Processed 2880/22500 samples\n",
            "  Processed 3200/22500 samples\n",
            "  Processed 3520/22500 samples\n",
            "  Processed 3840/22500 samples\n",
            "  Processed 4160/22500 samples\n",
            "  Processed 4480/22500 samples\n",
            "  Processed 4800/22500 samples\n",
            "  Processed 5120/22500 samples\n",
            "  Processed 5440/22500 samples\n",
            "  Processed 5760/22500 samples\n",
            "  Processed 6080/22500 samples\n",
            "  Processed 6400/22500 samples\n",
            "  Processed 6720/22500 samples\n",
            "  Processed 7040/22500 samples\n",
            "  Processed 7360/22500 samples\n",
            "  Processed 7680/22500 samples\n",
            "  Processed 8000/22500 samples\n",
            "  Processed 8320/22500 samples\n",
            "  Processed 8640/22500 samples\n",
            "  Processed 8960/22500 samples\n",
            "  Processed 9280/22500 samples\n",
            "  Processed 9600/22500 samples\n",
            "  Processed 9920/22500 samples\n",
            "  Processed 10240/22500 samples\n",
            "  Processed 10560/22500 samples\n",
            "  Processed 10880/22500 samples\n",
            "  Processed 11200/22500 samples\n",
            "  Processed 11520/22500 samples\n",
            "  Processed 11840/22500 samples\n",
            "  Processed 12160/22500 samples\n",
            "  Processed 12480/22500 samples\n",
            "  Processed 12800/22500 samples\n",
            "  Processed 13120/22500 samples\n",
            "  Processed 13440/22500 samples\n",
            "  Processed 13760/22500 samples\n",
            "  Processed 14080/22500 samples\n",
            "  Processed 14400/22500 samples\n",
            "  Processed 14720/22500 samples\n",
            "  Processed 15040/22500 samples\n",
            "  Processed 15360/22500 samples\n",
            "  Processed 15680/22500 samples\n",
            "  Processed 16000/22500 samples\n",
            "  Processed 16320/22500 samples\n",
            "  Processed 16640/22500 samples\n",
            "  Processed 16960/22500 samples\n",
            "  Processed 17280/22500 samples\n",
            "  Processed 17600/22500 samples\n",
            "  Processed 17920/22500 samples\n",
            "  Processed 18240/22500 samples\n",
            "  Processed 18560/22500 samples\n",
            "  Processed 18880/22500 samples\n",
            "  Processed 19200/22500 samples\n",
            "  Processed 19520/22500 samples\n",
            "  Processed 19840/22500 samples\n",
            "  Processed 20160/22500 samples\n",
            "  Processed 20480/22500 samples\n",
            "  Processed 20800/22500 samples\n",
            "  Processed 21120/22500 samples\n",
            "  Processed 21440/22500 samples\n",
            "  Processed 21760/22500 samples\n",
            "  Processed 22080/22500 samples\n",
            "  Processed 22400/22500 samples\n",
            "✓ Embeddings extracted: (22500, 300)\n",
            "\n",
            "Extracting embeddings for 2500 samples...\n",
            "  Processed 320/2500 samples\n",
            "  Processed 640/2500 samples\n",
            "  Processed 960/2500 samples\n",
            "  Processed 1280/2500 samples\n",
            "  Processed 1600/2500 samples\n",
            "  Processed 1920/2500 samples\n",
            "  Processed 2240/2500 samples\n",
            "✓ Embeddings extracted: (2500, 300)\n",
            "\n",
            "Extracting embeddings for 25000 samples...\n",
            "  Processed 320/25000 samples\n",
            "  Processed 640/25000 samples\n",
            "  Processed 960/25000 samples\n",
            "  Processed 1280/25000 samples\n",
            "  Processed 1600/25000 samples\n",
            "  Processed 1920/25000 samples\n",
            "  Processed 2240/25000 samples\n",
            "  Processed 2560/25000 samples\n",
            "  Processed 2880/25000 samples\n",
            "  Processed 3200/25000 samples\n",
            "  Processed 3520/25000 samples\n",
            "  Processed 3840/25000 samples\n",
            "  Processed 4160/25000 samples\n",
            "  Processed 4480/25000 samples\n",
            "  Processed 4800/25000 samples\n",
            "  Processed 5120/25000 samples\n",
            "  Processed 5440/25000 samples\n",
            "  Processed 5760/25000 samples\n",
            "  Processed 6080/25000 samples\n",
            "  Processed 6400/25000 samples\n",
            "  Processed 6720/25000 samples\n",
            "  Processed 7040/25000 samples\n",
            "  Processed 7360/25000 samples\n",
            "  Processed 7680/25000 samples\n",
            "  Processed 8000/25000 samples\n",
            "  Processed 8320/25000 samples\n",
            "  Processed 8640/25000 samples\n",
            "  Processed 8960/25000 samples\n",
            "  Processed 9280/25000 samples\n",
            "  Processed 9600/25000 samples\n",
            "  Processed 9920/25000 samples\n",
            "  Processed 10240/25000 samples\n",
            "  Processed 10560/25000 samples\n",
            "  Processed 10880/25000 samples\n",
            "  Processed 11200/25000 samples\n",
            "  Processed 11520/25000 samples\n",
            "  Processed 11840/25000 samples\n",
            "  Processed 12160/25000 samples\n",
            "  Processed 12480/25000 samples\n",
            "  Processed 12800/25000 samples\n",
            "  Processed 13120/25000 samples\n",
            "  Processed 13440/25000 samples\n",
            "  Processed 13760/25000 samples\n",
            "  Processed 14080/25000 samples\n",
            "  Processed 14400/25000 samples\n",
            "  Processed 14720/25000 samples\n",
            "  Processed 15040/25000 samples\n",
            "  Processed 15360/25000 samples\n",
            "  Processed 15680/25000 samples\n",
            "  Processed 16000/25000 samples\n",
            "  Processed 16320/25000 samples\n",
            "  Processed 16640/25000 samples\n",
            "  Processed 16960/25000 samples\n",
            "  Processed 17280/25000 samples\n",
            "  Processed 17600/25000 samples\n",
            "  Processed 17920/25000 samples\n",
            "  Processed 18240/25000 samples\n",
            "  Processed 18560/25000 samples\n",
            "  Processed 18880/25000 samples\n",
            "  Processed 19200/25000 samples\n",
            "  Processed 19520/25000 samples\n",
            "  Processed 19840/25000 samples\n",
            "  Processed 20160/25000 samples\n",
            "  Processed 20480/25000 samples\n",
            "  Processed 20800/25000 samples\n",
            "  Processed 21120/25000 samples\n",
            "  Processed 21440/25000 samples\n",
            "  Processed 21760/25000 samples\n",
            "  Processed 22080/25000 samples\n",
            "  Processed 22400/25000 samples\n",
            "  Processed 22720/25000 samples\n",
            "  Processed 23040/25000 samples\n",
            "  Processed 23360/25000 samples\n",
            "  Processed 23680/25000 samples\n",
            "  Processed 24000/25000 samples\n",
            "  Processed 24320/25000 samples\n",
            "  Processed 24640/25000 samples\n",
            "  Processed 24960/25000 samples\n",
            "✓ Embeddings extracted: (25000, 300)\n",
            "\n",
            "============================================================\n",
            "Training LOGISTIC_REGRESSION\n",
            "============================================================\n",
            "Training Logistic Regression...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 300\n",
            "  C (regularization): 0.01\n",
            "  Penalty: l1\n",
            "  Solver: liblinear\n",
            "  Normalize: True\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.7076\n",
            "  Validation accuracy: 0.6932\n",
            "  Iterations: 13\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.6906\n",
            "  Precision: 0.6987\n",
            "  Recall:    0.6704\n",
            "  F1 Score:  0.6842\n",
            "  ROC-AUC:   0.7590\n",
            "Model saved to results/models/classical_ml/imdb/transformer/logistic_regression.pkl\n",
            "\n",
            "============================================================\n",
            "Training RANDOM_FOREST\n",
            "============================================================\n",
            "Training Random Forest...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 300\n",
            "  Number of trees: 100\n",
            "  Max depth: 10\n",
            "  Max features: sqrt\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.9210\n",
            "  Validation accuracy: 0.6404\n",
            "  Number of trees: 100\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.6410\n",
            "  Precision: 0.6485\n",
            "  Recall:    0.6158\n",
            "  F1 Score:  0.6317\n",
            "  ROC-AUC:   0.6974\n",
            "Model saved to results/models/classical_ml/imdb/transformer/random_forest.pkl\n",
            "\n",
            "============================================================\n",
            "Training XGBOOST\n",
            "============================================================\n",
            "Training XGBoost...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 300\n",
            "  Number of estimators: 100\n",
            "  Max depth: 3\n",
            "  Learning rate: 0.01\n",
            "  Subsample: 0.8\n",
            "  Colsample by tree: 0.8\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [16:36:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.6353\n",
            "  Validation accuracy: 0.6100\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.6139\n",
            "  Precision: 0.6224\n",
            "  Recall:    0.5794\n",
            "  F1 Score:  0.6001\n",
            "  ROC-AUC:   0.6569\n",
            "Model saved to results/models/classical_ml/imdb/transformer/xgboost.pkl\n",
            "\n",
            "✓ Results saved to results/classical_ml/imdb/transformer/results_20251201_163616.pkl\n",
            "\n",
            "============================================================\n",
            "RESULTS SUMMARY\n",
            "============================================================\n",
            "Model                Train Acc    Val Acc      Test Acc     Test F1     \n",
            "------------------------------------------------------------\n",
            "logistic_regression  0.7076       0.6932       0.6906       0.6842      \n",
            "random_forest        0.9210       0.6404       0.6410       0.6317      \n",
            "xgboost              0.6353       0.6100       0.6139       0.6001      \n",
            "\n",
            "✓ Training complete!\n"
          ]
        }
      ],
      "source": [
        "# train hybrid models (Transformer + Classical ML)\n",
        "\n",
        "!python src/training/train_classical_ml.py \\\n",
        "    --dataset {dataset_arg} \\\n",
        "    --encoder transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8a9ee29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8a9ee29",
        "outputId": "dcb70935-a214-410c-c8ab-bc5723f296a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set to 42\n",
            "Initialized ClassicalMLTrainer\n",
            "  Encoder type: bert\n",
            "  Device: cuda\n",
            "\n",
            "============================================================\n",
            "Training Classical ML Models on IMDB\n",
            "============================================================\n",
            "\n",
            "Loading dataset...\n",
            "Loaded dataset from cache: data/processed/imdb_cache.pkl\n",
            "\n",
            "Building vocabulary...\n",
            "Building vocabulary...\n",
            "Vocabulary size: 20000\n",
            "Most common words: ['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
            "\n",
            "Loading bert encoder...\n",
            "  No pre-trained encoder found, using random initialization\n",
            "2025-12-01 16:44:17.251433: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764607457.273862   43496 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764607457.280892   43496 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764607457.298069   43496 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764607457.298098   43496 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764607457.298102   43496 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764607457.298107   43496 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-01 16:44:17.303974: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "✓ Random encoder initialized\n",
            "\n",
            "Extracting embeddings for 22500 samples...\n",
            "  Processed 320/22500 samples\n",
            "  Processed 640/22500 samples\n",
            "  Processed 960/22500 samples\n",
            "  Processed 1280/22500 samples\n",
            "  Processed 1600/22500 samples\n",
            "  Processed 1920/22500 samples\n",
            "  Processed 2240/22500 samples\n",
            "  Processed 2560/22500 samples\n",
            "  Processed 2880/22500 samples\n",
            "  Processed 3200/22500 samples\n",
            "  Processed 3520/22500 samples\n",
            "  Processed 3840/22500 samples\n",
            "  Processed 4160/22500 samples\n",
            "  Processed 4480/22500 samples\n",
            "  Processed 4800/22500 samples\n",
            "  Processed 5120/22500 samples\n",
            "  Processed 5440/22500 samples\n",
            "  Processed 5760/22500 samples\n",
            "  Processed 6080/22500 samples\n",
            "  Processed 6400/22500 samples\n",
            "  Processed 6720/22500 samples\n",
            "  Processed 7040/22500 samples\n",
            "  Processed 7360/22500 samples\n",
            "  Processed 7680/22500 samples\n",
            "  Processed 8000/22500 samples\n",
            "  Processed 8320/22500 samples\n",
            "  Processed 8640/22500 samples\n",
            "  Processed 8960/22500 samples\n",
            "  Processed 9280/22500 samples\n",
            "  Processed 9600/22500 samples\n",
            "  Processed 9920/22500 samples\n",
            "  Processed 10240/22500 samples\n",
            "  Processed 10560/22500 samples\n",
            "  Processed 10880/22500 samples\n",
            "  Processed 11200/22500 samples\n",
            "  Processed 11520/22500 samples\n",
            "  Processed 11840/22500 samples\n",
            "  Processed 12160/22500 samples\n",
            "  Processed 12480/22500 samples\n",
            "  Processed 12800/22500 samples\n",
            "  Processed 13120/22500 samples\n",
            "  Processed 13440/22500 samples\n",
            "  Processed 13760/22500 samples\n",
            "  Processed 14080/22500 samples\n",
            "  Processed 14400/22500 samples\n",
            "  Processed 14720/22500 samples\n",
            "  Processed 15040/22500 samples\n",
            "  Processed 15360/22500 samples\n",
            "  Processed 15680/22500 samples\n",
            "  Processed 16000/22500 samples\n",
            "  Processed 16320/22500 samples\n",
            "  Processed 16640/22500 samples\n",
            "  Processed 16960/22500 samples\n",
            "  Processed 17280/22500 samples\n",
            "  Processed 17600/22500 samples\n",
            "  Processed 17920/22500 samples\n",
            "  Processed 18240/22500 samples\n",
            "  Processed 18560/22500 samples\n",
            "  Processed 18880/22500 samples\n",
            "  Processed 19200/22500 samples\n",
            "  Processed 19520/22500 samples\n",
            "  Processed 19840/22500 samples\n",
            "  Processed 20160/22500 samples\n",
            "  Processed 20480/22500 samples\n",
            "  Processed 20800/22500 samples\n",
            "  Processed 21120/22500 samples\n",
            "  Processed 21440/22500 samples\n",
            "  Processed 21760/22500 samples\n",
            "  Processed 22080/22500 samples\n",
            "  Processed 22400/22500 samples\n",
            "✓ Embeddings extracted: (22500, 768)\n",
            "\n",
            "Extracting embeddings for 2500 samples...\n",
            "  Processed 320/2500 samples\n",
            "  Processed 640/2500 samples\n",
            "  Processed 960/2500 samples\n",
            "  Processed 1280/2500 samples\n",
            "  Processed 1600/2500 samples\n",
            "  Processed 1920/2500 samples\n",
            "  Processed 2240/2500 samples\n",
            "✓ Embeddings extracted: (2500, 768)\n",
            "\n",
            "Extracting embeddings for 25000 samples...\n",
            "  Processed 320/25000 samples\n",
            "  Processed 640/25000 samples\n",
            "  Processed 960/25000 samples\n",
            "  Processed 1280/25000 samples\n",
            "  Processed 1600/25000 samples\n",
            "  Processed 1920/25000 samples\n",
            "  Processed 2240/25000 samples\n",
            "  Processed 2560/25000 samples\n",
            "  Processed 2880/25000 samples\n",
            "  Processed 3200/25000 samples\n",
            "  Processed 3520/25000 samples\n",
            "  Processed 3840/25000 samples\n",
            "  Processed 4160/25000 samples\n",
            "  Processed 4480/25000 samples\n",
            "  Processed 4800/25000 samples\n",
            "  Processed 5120/25000 samples\n",
            "  Processed 5440/25000 samples\n",
            "  Processed 5760/25000 samples\n",
            "  Processed 6080/25000 samples\n",
            "  Processed 6400/25000 samples\n",
            "  Processed 6720/25000 samples\n",
            "  Processed 7040/25000 samples\n",
            "  Processed 7360/25000 samples\n",
            "  Processed 7680/25000 samples\n",
            "  Processed 8000/25000 samples\n",
            "  Processed 8320/25000 samples\n",
            "  Processed 8640/25000 samples\n",
            "  Processed 8960/25000 samples\n",
            "  Processed 9280/25000 samples\n",
            "  Processed 9600/25000 samples\n",
            "  Processed 9920/25000 samples\n",
            "  Processed 10240/25000 samples\n",
            "  Processed 10560/25000 samples\n",
            "  Processed 10880/25000 samples\n",
            "  Processed 11200/25000 samples\n",
            "  Processed 11520/25000 samples\n",
            "  Processed 11840/25000 samples\n",
            "  Processed 12160/25000 samples\n",
            "  Processed 12480/25000 samples\n",
            "  Processed 12800/25000 samples\n",
            "  Processed 13120/25000 samples\n",
            "  Processed 13440/25000 samples\n",
            "  Processed 13760/25000 samples\n",
            "  Processed 14080/25000 samples\n",
            "  Processed 14400/25000 samples\n",
            "  Processed 14720/25000 samples\n",
            "  Processed 15040/25000 samples\n",
            "  Processed 15360/25000 samples\n",
            "  Processed 15680/25000 samples\n",
            "  Processed 16000/25000 samples\n",
            "  Processed 16320/25000 samples\n",
            "  Processed 16640/25000 samples\n",
            "  Processed 16960/25000 samples\n",
            "  Processed 17280/25000 samples\n",
            "  Processed 17600/25000 samples\n",
            "  Processed 17920/25000 samples\n",
            "  Processed 18240/25000 samples\n",
            "  Processed 18560/25000 samples\n",
            "  Processed 18880/25000 samples\n",
            "  Processed 19200/25000 samples\n",
            "  Processed 19520/25000 samples\n",
            "  Processed 19840/25000 samples\n",
            "  Processed 20160/25000 samples\n",
            "  Processed 20480/25000 samples\n",
            "  Processed 20800/25000 samples\n",
            "  Processed 21120/25000 samples\n",
            "  Processed 21440/25000 samples\n",
            "  Processed 21760/25000 samples\n",
            "  Processed 22080/25000 samples\n",
            "  Processed 22400/25000 samples\n",
            "  Processed 22720/25000 samples\n",
            "  Processed 23040/25000 samples\n",
            "  Processed 23360/25000 samples\n",
            "  Processed 23680/25000 samples\n",
            "  Processed 24000/25000 samples\n",
            "  Processed 24320/25000 samples\n",
            "  Processed 24640/25000 samples\n",
            "  Processed 24960/25000 samples\n",
            "✓ Embeddings extracted: (25000, 768)\n",
            "\n",
            "============================================================\n",
            "Training LOGISTIC_REGRESSION\n",
            "============================================================\n",
            "Training Logistic Regression...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 768\n",
            "  C (regularization): 0.01\n",
            "  Penalty: l1\n",
            "  Solver: liblinear\n",
            "  Normalize: True\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.8647\n",
            "  Validation accuracy: 0.8584\n",
            "  Iterations: 12\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.8619\n",
            "  Precision: 0.8715\n",
            "  Recall:    0.8490\n",
            "  F1 Score:  0.8601\n",
            "  ROC-AUC:   0.9354\n",
            "Model saved to results/models/classical_ml/imdb/bert/logistic_regression.pkl\n",
            "\n",
            "============================================================\n",
            "Training RANDOM_FOREST\n",
            "============================================================\n",
            "Training Random Forest...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 768\n",
            "  Number of trees: 100\n",
            "  Max depth: 10\n",
            "  Max features: sqrt\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.9484\n",
            "  Validation accuracy: 0.8268\n",
            "  Number of trees: 100\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.8218\n",
            "  Precision: 0.8326\n",
            "  Recall:    0.8057\n",
            "  F1 Score:  0.8189\n",
            "  ROC-AUC:   0.9013\n",
            "Model saved to results/models/classical_ml/imdb/bert/random_forest.pkl\n",
            "\n",
            "============================================================\n",
            "Training XGBOOST\n",
            "============================================================\n",
            "Training XGBoost...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 768\n",
            "  Number of estimators: 100\n",
            "  Max depth: 3\n",
            "  Learning rate: 0.01\n",
            "  Subsample: 0.8\n",
            "  Colsample by tree: 0.8\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:12:40] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.7905\n",
            "  Validation accuracy: 0.7808\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.7768\n",
            "  Precision: 0.7909\n",
            "  Recall:    0.7526\n",
            "  F1 Score:  0.7713\n",
            "  ROC-AUC:   0.8604\n",
            "Model saved to results/models/classical_ml/imdb/bert/xgboost.pkl\n",
            "\n",
            "✓ Results saved to results/classical_ml/imdb/bert/results_20251201_171253.pkl\n",
            "\n",
            "============================================================\n",
            "RESULTS SUMMARY\n",
            "============================================================\n",
            "Model                Train Acc    Val Acc      Test Acc     Test F1     \n",
            "------------------------------------------------------------\n",
            "logistic_regression  0.8647       0.8584       0.8619       0.8601      \n",
            "random_forest        0.9484       0.8268       0.8218       0.8189      \n",
            "xgboost              0.7905       0.7808       0.7768       0.7713      \n",
            "\n",
            "✓ Training complete!\n",
            "Hybrid BERT models trained on IMDB dataset\n"
          ]
        }
      ],
      "source": [
        "!python src/training/train_classical_ml.py \\\n",
        "    --dataset {dataset_arg} \\\n",
        "    --encoder bert\n",
        "\n",
        "print(f\"Hybrid BERT models trained on {dataset_arg.upper()} dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ed8713b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ed8713b",
        "outputId": "4bb125b3-53dd-4e59-fac9-87431806a20d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set to 42\n",
            "Initialized ClassicalMLTrainer\n",
            "  Encoder type: roberta\n",
            "  Device: cuda\n",
            "\n",
            "============================================================\n",
            "Training Classical ML Models on IMDB\n",
            "============================================================\n",
            "\n",
            "Loading dataset...\n",
            "Loaded dataset from cache: data/processed/imdb_cache.pkl\n",
            "\n",
            "Building vocabulary...\n",
            "Building vocabulary...\n",
            "Vocabulary size: 20000\n",
            "Most common words: ['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
            "\n",
            "Loading roberta encoder...\n",
            "  No pre-trained encoder found, using random initialization\n",
            "2025-12-02 15:37:51.422653: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764689871.446467   48169 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764689871.453424   48169 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764689871.471451   48169 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764689871.471493   48169 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764689871.471498   48169 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764689871.471504   48169 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 15:37:51.476978: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "✓ Random encoder initialized\n",
            "\n",
            "Extracting embeddings for 22500 samples...\n",
            "  Processed 320/22500 samples\n",
            "  Processed 640/22500 samples\n",
            "  Processed 960/22500 samples\n",
            "  Processed 1280/22500 samples\n",
            "  Processed 1600/22500 samples\n",
            "  Processed 1920/22500 samples\n",
            "  Processed 2240/22500 samples\n",
            "  Processed 2560/22500 samples\n",
            "  Processed 2880/22500 samples\n",
            "  Processed 3200/22500 samples\n",
            "  Processed 3520/22500 samples\n",
            "  Processed 3840/22500 samples\n",
            "  Processed 4160/22500 samples\n",
            "  Processed 4480/22500 samples\n",
            "  Processed 4800/22500 samples\n",
            "  Processed 5120/22500 samples\n",
            "  Processed 5440/22500 samples\n",
            "  Processed 5760/22500 samples\n",
            "  Processed 6080/22500 samples\n",
            "  Processed 6400/22500 samples\n",
            "  Processed 6720/22500 samples\n",
            "  Processed 7040/22500 samples\n",
            "  Processed 7360/22500 samples\n",
            "  Processed 7680/22500 samples\n",
            "  Processed 8000/22500 samples\n",
            "  Processed 8320/22500 samples\n",
            "  Processed 8640/22500 samples\n",
            "  Processed 8960/22500 samples\n",
            "  Processed 9280/22500 samples\n",
            "  Processed 9600/22500 samples\n",
            "  Processed 9920/22500 samples\n",
            "  Processed 10240/22500 samples\n",
            "  Processed 10560/22500 samples\n",
            "  Processed 10880/22500 samples\n",
            "  Processed 11200/22500 samples\n",
            "  Processed 11520/22500 samples\n",
            "  Processed 11840/22500 samples\n",
            "  Processed 12160/22500 samples\n",
            "  Processed 12480/22500 samples\n",
            "  Processed 12800/22500 samples\n",
            "  Processed 13120/22500 samples\n",
            "  Processed 13440/22500 samples\n",
            "  Processed 13760/22500 samples\n",
            "  Processed 14080/22500 samples\n",
            "  Processed 14400/22500 samples\n",
            "  Processed 14720/22500 samples\n",
            "  Processed 15040/22500 samples\n",
            "  Processed 15360/22500 samples\n",
            "  Processed 15680/22500 samples\n",
            "  Processed 16000/22500 samples\n",
            "  Processed 16320/22500 samples\n",
            "  Processed 16640/22500 samples\n",
            "  Processed 16960/22500 samples\n",
            "  Processed 17280/22500 samples\n",
            "  Processed 17600/22500 samples\n",
            "  Processed 17920/22500 samples\n",
            "  Processed 18240/22500 samples\n",
            "  Processed 18560/22500 samples\n",
            "  Processed 18880/22500 samples\n",
            "  Processed 19200/22500 samples\n",
            "  Processed 19520/22500 samples\n",
            "  Processed 19840/22500 samples\n",
            "  Processed 20160/22500 samples\n",
            "  Processed 20480/22500 samples\n",
            "  Processed 20800/22500 samples\n",
            "  Processed 21120/22500 samples\n",
            "  Processed 21440/22500 samples\n",
            "  Processed 21760/22500 samples\n",
            "  Processed 22080/22500 samples\n",
            "  Processed 22400/22500 samples\n",
            "✓ Embeddings extracted: (22500, 768)\n",
            "\n",
            "Extracting embeddings for 2500 samples...\n",
            "  Processed 320/2500 samples\n",
            "  Processed 640/2500 samples\n",
            "  Processed 960/2500 samples\n",
            "  Processed 1280/2500 samples\n",
            "  Processed 1600/2500 samples\n",
            "  Processed 1920/2500 samples\n",
            "  Processed 2240/2500 samples\n",
            "✓ Embeddings extracted: (2500, 768)\n",
            "\n",
            "Extracting embeddings for 25000 samples...\n",
            "  Processed 320/25000 samples\n",
            "  Processed 640/25000 samples\n",
            "  Processed 960/25000 samples\n",
            "  Processed 1280/25000 samples\n",
            "  Processed 1600/25000 samples\n",
            "  Processed 1920/25000 samples\n",
            "  Processed 2240/25000 samples\n",
            "  Processed 2560/25000 samples\n",
            "  Processed 2880/25000 samples\n",
            "  Processed 3200/25000 samples\n",
            "  Processed 3520/25000 samples\n",
            "  Processed 3840/25000 samples\n",
            "  Processed 4160/25000 samples\n",
            "  Processed 4480/25000 samples\n",
            "  Processed 4800/25000 samples\n",
            "  Processed 5120/25000 samples\n",
            "  Processed 5440/25000 samples\n",
            "  Processed 5760/25000 samples\n",
            "  Processed 6080/25000 samples\n",
            "  Processed 6400/25000 samples\n",
            "  Processed 6720/25000 samples\n",
            "  Processed 7040/25000 samples\n",
            "  Processed 7360/25000 samples\n",
            "  Processed 7680/25000 samples\n",
            "  Processed 8000/25000 samples\n",
            "  Processed 8320/25000 samples\n",
            "  Processed 8640/25000 samples\n",
            "  Processed 8960/25000 samples\n",
            "  Processed 9280/25000 samples\n",
            "  Processed 9600/25000 samples\n",
            "  Processed 9920/25000 samples\n",
            "  Processed 10240/25000 samples\n",
            "  Processed 10560/25000 samples\n",
            "  Processed 10880/25000 samples\n",
            "  Processed 11200/25000 samples\n",
            "  Processed 11520/25000 samples\n",
            "  Processed 11840/25000 samples\n",
            "  Processed 12160/25000 samples\n",
            "  Processed 12480/25000 samples\n",
            "  Processed 12800/25000 samples\n",
            "  Processed 13120/25000 samples\n",
            "  Processed 13440/25000 samples\n",
            "  Processed 13760/25000 samples\n",
            "  Processed 14080/25000 samples\n",
            "  Processed 14400/25000 samples\n",
            "  Processed 14720/25000 samples\n",
            "  Processed 15040/25000 samples\n",
            "  Processed 15360/25000 samples\n",
            "  Processed 15680/25000 samples\n",
            "  Processed 16000/25000 samples\n",
            "  Processed 16320/25000 samples\n",
            "  Processed 16640/25000 samples\n",
            "  Processed 16960/25000 samples\n",
            "  Processed 17280/25000 samples\n",
            "  Processed 17600/25000 samples\n",
            "  Processed 17920/25000 samples\n",
            "  Processed 18240/25000 samples\n",
            "  Processed 18560/25000 samples\n",
            "  Processed 18880/25000 samples\n",
            "  Processed 19200/25000 samples\n",
            "  Processed 19520/25000 samples\n",
            "  Processed 19840/25000 samples\n",
            "  Processed 20160/25000 samples\n",
            "  Processed 20480/25000 samples\n",
            "  Processed 20800/25000 samples\n",
            "  Processed 21120/25000 samples\n",
            "  Processed 21440/25000 samples\n",
            "  Processed 21760/25000 samples\n",
            "  Processed 22080/25000 samples\n",
            "  Processed 22400/25000 samples\n",
            "  Processed 22720/25000 samples\n",
            "  Processed 23040/25000 samples\n",
            "  Processed 23360/25000 samples\n",
            "  Processed 23680/25000 samples\n",
            "  Processed 24000/25000 samples\n",
            "  Processed 24320/25000 samples\n",
            "  Processed 24640/25000 samples\n",
            "  Processed 24960/25000 samples\n",
            "✓ Embeddings extracted: (25000, 768)\n",
            "\n",
            "============================================================\n",
            "Training LOGISTIC_REGRESSION\n",
            "============================================================\n",
            "Training Logistic Regression...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 768\n",
            "  C (regularization): 0.01\n",
            "  Penalty: l1\n",
            "  Solver: liblinear\n",
            "  Normalize: True\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.9054\n",
            "  Validation accuracy: 0.9020\n",
            "  Iterations: 11\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.9048\n",
            "  Precision: 0.9047\n",
            "  Recall:    0.9049\n",
            "  F1 Score:  0.9048\n",
            "  ROC-AUC:   0.9653\n",
            "Model saved to results/models/classical_ml/imdb/roberta/logistic_regression.pkl\n",
            "\n",
            "============================================================\n",
            "Training RANDOM_FOREST\n",
            "============================================================\n",
            "Training Random Forest...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 768\n",
            "  Number of trees: 100\n",
            "  Max depth: 10\n",
            "  Max features: sqrt\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.9684\n",
            "  Validation accuracy: 0.8500\n",
            "  Number of trees: 100\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.8512\n",
            "  Precision: 0.8477\n",
            "  Recall:    0.8562\n",
            "  F1 Score:  0.8519\n",
            "  ROC-AUC:   0.9290\n",
            "Model saved to results/models/classical_ml/imdb/roberta/random_forest.pkl\n",
            "\n",
            "============================================================\n",
            "Training XGBOOST\n",
            "============================================================\n",
            "Training XGBoost...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 768\n",
            "  Number of estimators: 100\n",
            "  Max depth: 3\n",
            "  Learning rate: 0.01\n",
            "  Subsample: 0.8\n",
            "  Colsample by tree: 0.8\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [16:03:01] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.7905\n",
            "  Validation accuracy: 0.7748\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.7729\n",
            "  Precision: 0.7828\n",
            "  Recall:    0.7555\n",
            "  F1 Score:  0.7689\n",
            "  ROC-AUC:   0.8640\n",
            "Model saved to results/models/classical_ml/imdb/roberta/xgboost.pkl\n",
            "\n",
            "✓ Results saved to results/classical_ml/imdb/roberta/results_20251202_160315.pkl\n",
            "\n",
            "============================================================\n",
            "RESULTS SUMMARY\n",
            "============================================================\n",
            "Model                Train Acc    Val Acc      Test Acc     Test F1     \n",
            "------------------------------------------------------------\n",
            "logistic_regression  0.9054       0.9020       0.9048       0.9048      \n",
            "random_forest        0.9684       0.8500       0.8512       0.8519      \n",
            "xgboost              0.7905       0.7748       0.7729       0.7689      \n",
            "\n",
            "✓ Training complete!\n",
            "Hybrid RoBERTa models trained on IMDB dataset\n"
          ]
        }
      ],
      "source": [
        "!python src/training/train_classical_ml.py \\\n",
        "    --dataset {dataset_arg} \\\n",
        "    --encoder roberta\n",
        "\n",
        "print(f\"Hybrid RoBERTa models trained on {dataset_arg.upper()} dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-d1omYpZxW8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d1omYpZxW8c",
        "outputId": "22c6c820-eef9-4e49-f219-fa6a3821ea56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set to 42\n",
            "Initialized ClassicalMLTrainer\n",
            "  Encoder type: distilbert\n",
            "  Device: cuda\n",
            "\n",
            "============================================================\n",
            "Training Classical ML Models on IMDB\n",
            "============================================================\n",
            "\n",
            "Loading dataset...\n",
            "Loaded dataset from cache: data/processed/imdb_cache.pkl\n",
            "\n",
            "Building vocabulary...\n",
            "Building vocabulary...\n",
            "Vocabulary size: 20000\n",
            "Most common words: ['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
            "\n",
            "Loading distilbert encoder...\n",
            "  No pre-trained encoder found, using random initialization\n",
            "2025-12-02 16:03:52.229106: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764691432.267995   54665 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764691432.279540   54665 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764691432.308623   54665 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764691432.308677   54665 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764691432.308686   54665 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764691432.308694   54665 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-02 16:03:52.316872: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "✓ Random encoder initialized\n",
            "\n",
            "Extracting embeddings for 22500 samples...\n",
            "  Processed 320/22500 samples\n",
            "  Processed 640/22500 samples\n",
            "  Processed 960/22500 samples\n",
            "  Processed 1280/22500 samples\n",
            "  Processed 1600/22500 samples\n",
            "  Processed 1920/22500 samples\n",
            "  Processed 2240/22500 samples\n",
            "  Processed 2560/22500 samples\n",
            "  Processed 2880/22500 samples\n",
            "  Processed 3200/22500 samples\n",
            "  Processed 3520/22500 samples\n",
            "  Processed 3840/22500 samples\n",
            "  Processed 4160/22500 samples\n",
            "  Processed 4480/22500 samples\n",
            "  Processed 4800/22500 samples\n",
            "  Processed 5120/22500 samples\n",
            "  Processed 5440/22500 samples\n",
            "  Processed 5760/22500 samples\n",
            "  Processed 6080/22500 samples\n",
            "  Processed 6400/22500 samples\n",
            "  Processed 6720/22500 samples\n",
            "  Processed 7040/22500 samples\n",
            "  Processed 7360/22500 samples\n",
            "  Processed 7680/22500 samples\n",
            "  Processed 8000/22500 samples\n",
            "  Processed 8320/22500 samples\n",
            "  Processed 8640/22500 samples\n",
            "  Processed 8960/22500 samples\n",
            "  Processed 9280/22500 samples\n",
            "  Processed 9600/22500 samples\n",
            "  Processed 9920/22500 samples\n",
            "  Processed 10240/22500 samples\n",
            "  Processed 10560/22500 samples\n",
            "  Processed 10880/22500 samples\n",
            "  Processed 11200/22500 samples\n",
            "  Processed 11520/22500 samples\n",
            "  Processed 11840/22500 samples\n",
            "  Processed 12160/22500 samples\n",
            "  Processed 12480/22500 samples\n",
            "  Processed 12800/22500 samples\n",
            "  Processed 13120/22500 samples\n",
            "  Processed 13440/22500 samples\n",
            "  Processed 13760/22500 samples\n",
            "  Processed 14080/22500 samples\n",
            "  Processed 14400/22500 samples\n",
            "  Processed 14720/22500 samples\n",
            "  Processed 15040/22500 samples\n",
            "  Processed 15360/22500 samples\n",
            "  Processed 15680/22500 samples\n",
            "  Processed 16000/22500 samples\n",
            "  Processed 16320/22500 samples\n",
            "  Processed 16640/22500 samples\n",
            "  Processed 16960/22500 samples\n",
            "  Processed 17280/22500 samples\n",
            "  Processed 17600/22500 samples\n",
            "  Processed 17920/22500 samples\n",
            "  Processed 18240/22500 samples\n",
            "  Processed 18560/22500 samples\n",
            "  Processed 18880/22500 samples\n",
            "  Processed 19200/22500 samples\n",
            "  Processed 19520/22500 samples\n",
            "  Processed 19840/22500 samples\n",
            "  Processed 20160/22500 samples\n",
            "  Processed 20480/22500 samples\n",
            "  Processed 20800/22500 samples\n",
            "  Processed 21120/22500 samples\n",
            "  Processed 21440/22500 samples\n",
            "  Processed 21760/22500 samples\n",
            "  Processed 22080/22500 samples\n",
            "  Processed 22400/22500 samples\n",
            "✓ Embeddings extracted: (22500, 768)\n",
            "\n",
            "Extracting embeddings for 2500 samples...\n",
            "  Processed 320/2500 samples\n",
            "  Processed 640/2500 samples\n",
            "  Processed 960/2500 samples\n",
            "  Processed 1280/2500 samples\n",
            "  Processed 1600/2500 samples\n",
            "  Processed 1920/2500 samples\n",
            "  Processed 2240/2500 samples\n",
            "✓ Embeddings extracted: (2500, 768)\n",
            "\n",
            "Extracting embeddings for 25000 samples...\n",
            "  Processed 320/25000 samples\n",
            "  Processed 640/25000 samples\n",
            "  Processed 960/25000 samples\n",
            "  Processed 1280/25000 samples\n",
            "  Processed 1600/25000 samples\n",
            "  Processed 1920/25000 samples\n",
            "  Processed 2240/25000 samples\n",
            "  Processed 2560/25000 samples\n",
            "  Processed 2880/25000 samples\n",
            "  Processed 3200/25000 samples\n",
            "  Processed 3520/25000 samples\n",
            "  Processed 3840/25000 samples\n",
            "  Processed 4160/25000 samples\n",
            "  Processed 4480/25000 samples\n",
            "  Processed 4800/25000 samples\n",
            "  Processed 5120/25000 samples\n",
            "  Processed 5440/25000 samples\n",
            "  Processed 5760/25000 samples\n",
            "  Processed 6080/25000 samples\n",
            "  Processed 6400/25000 samples\n",
            "  Processed 6720/25000 samples\n",
            "  Processed 7040/25000 samples\n",
            "  Processed 7360/25000 samples\n",
            "  Processed 7680/25000 samples\n",
            "  Processed 8000/25000 samples\n",
            "  Processed 8320/25000 samples\n",
            "  Processed 8640/25000 samples\n",
            "  Processed 8960/25000 samples\n",
            "  Processed 9280/25000 samples\n",
            "  Processed 9600/25000 samples\n",
            "  Processed 9920/25000 samples\n",
            "  Processed 10240/25000 samples\n",
            "  Processed 10560/25000 samples\n",
            "  Processed 10880/25000 samples\n",
            "  Processed 11200/25000 samples\n",
            "  Processed 11520/25000 samples\n",
            "  Processed 11840/25000 samples\n",
            "  Processed 12160/25000 samples\n",
            "  Processed 12480/25000 samples\n",
            "  Processed 12800/25000 samples\n",
            "  Processed 13120/25000 samples\n",
            "  Processed 13440/25000 samples\n",
            "  Processed 13760/25000 samples\n",
            "  Processed 14080/25000 samples\n",
            "  Processed 14400/25000 samples\n",
            "  Processed 14720/25000 samples\n",
            "  Processed 15040/25000 samples\n",
            "  Processed 15360/25000 samples\n",
            "  Processed 15680/25000 samples\n",
            "  Processed 16000/25000 samples\n",
            "  Processed 16320/25000 samples\n",
            "  Processed 16640/25000 samples\n",
            "  Processed 16960/25000 samples\n",
            "  Processed 17280/25000 samples\n",
            "  Processed 17600/25000 samples\n",
            "  Processed 17920/25000 samples\n",
            "  Processed 18240/25000 samples\n",
            "  Processed 18560/25000 samples\n",
            "  Processed 18880/25000 samples\n",
            "  Processed 19200/25000 samples\n",
            "  Processed 19520/25000 samples\n",
            "  Processed 19840/25000 samples\n",
            "  Processed 20160/25000 samples\n",
            "  Processed 20480/25000 samples\n",
            "  Processed 20800/25000 samples\n",
            "  Processed 21120/25000 samples\n",
            "  Processed 21440/25000 samples\n",
            "  Processed 21760/25000 samples\n",
            "  Processed 22080/25000 samples\n",
            "  Processed 22400/25000 samples\n",
            "  Processed 22720/25000 samples\n",
            "  Processed 23040/25000 samples\n",
            "  Processed 23360/25000 samples\n",
            "  Processed 23680/25000 samples\n",
            "  Processed 24000/25000 samples\n",
            "  Processed 24320/25000 samples\n",
            "  Processed 24640/25000 samples\n",
            "  Processed 24960/25000 samples\n",
            "✓ Embeddings extracted: (25000, 768)\n",
            "\n",
            "============================================================\n",
            "Training LOGISTIC_REGRESSION\n",
            "============================================================\n",
            "Training Logistic Regression...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 768\n",
            "  C (regularization): 0.01\n",
            "  Penalty: l1\n",
            "  Solver: liblinear\n",
            "  Normalize: True\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.8672\n",
            "  Validation accuracy: 0.8748\n",
            "  Iterations: 11\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.8638\n",
            "  Precision: 0.8752\n",
            "  Recall:    0.8486\n",
            "  F1 Score:  0.8617\n",
            "  ROC-AUC:   0.9387\n",
            "Model saved to results/models/classical_ml/imdb/distilbert/logistic_regression.pkl\n",
            "\n",
            "============================================================\n",
            "Training RANDOM_FOREST\n",
            "============================================================\n",
            "Training Random Forest...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 768\n",
            "  Number of trees: 100\n",
            "  Max depth: 10\n",
            "  Max features: sqrt\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.9523\n",
            "  Validation accuracy: 0.8300\n",
            "  Number of trees: 100\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.8262\n",
            "  Precision: 0.8363\n",
            "  Recall:    0.8111\n",
            "  F1 Score:  0.8235\n",
            "  ROC-AUC:   0.9079\n",
            "Model saved to results/models/classical_ml/imdb/distilbert/random_forest.pkl\n",
            "\n",
            "============================================================\n",
            "Training XGBOOST\n",
            "============================================================\n",
            "Training XGBoost...\n",
            "  Training samples: 22500\n",
            "  Feature dimension: 768\n",
            "  Number of estimators: 100\n",
            "  Max depth: 3\n",
            "  Learning rate: 0.01\n",
            "  Subsample: 0.8\n",
            "  Colsample by tree: 0.8\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [16:18:46] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "✓ Training complete!\n",
            "  Train accuracy: 0.7920\n",
            "  Validation accuracy: 0.7912\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Results:\n",
            "  Accuracy:  0.7838\n",
            "  Precision: 0.7922\n",
            "  Recall:    0.7695\n",
            "  F1 Score:  0.7807\n",
            "  ROC-AUC:   0.8686\n",
            "Model saved to results/models/classical_ml/imdb/distilbert/xgboost.pkl\n",
            "\n",
            "✓ Results saved to results/classical_ml/imdb/distilbert/results_20251202_161900.pkl\n",
            "\n",
            "============================================================\n",
            "RESULTS SUMMARY\n",
            "============================================================\n",
            "Model                Train Acc    Val Acc      Test Acc     Test F1     \n",
            "------------------------------------------------------------\n",
            "logistic_regression  0.8672       0.8748       0.8638       0.8617      \n",
            "random_forest        0.9523       0.8300       0.8262       0.8235      \n",
            "xgboost              0.7920       0.7912       0.7838       0.7807      \n",
            "\n",
            "✓ Training complete!\n",
            "Hybrid DistilBERT models trained on IMDB dataset\n"
          ]
        }
      ],
      "source": [
        "!python src/training/train_classical_ml.py \\\n",
        "    --dataset {dataset_arg} \\\n",
        "    --encoder distilbert\n",
        "\n",
        "print(f\"Hybrid DistilBERT models trained on {dataset_arg.upper()} dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "956a82aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "956a82aa",
        "outputId": "91833402-9e2d-4ab2-db2d-08bf1b293dfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "object address  : 0x7984059d7580\n",
            "object refcount : 3\n",
            "object type     : 0xa2a4e0\n",
            "object type name: KeyboardInterrupt\n",
            "object repr     : KeyboardInterrupt()\n",
            "lost sys.stderr\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# compare ALL models\n",
        "\n",
        "!python src/evaluation/compare_models.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a934e7ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "a934e7ee",
        "outputId": "cb3f328b-c307-4913-dcea-e71f5eea25f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: results/ (stored 0%)\n",
            "  adding: results/models/ (stored 0%)\n",
            "  adding: results/models/deep_learning/ (stored 0%)\n",
            "  adding: results/models/deep_learning/imdb/ (stored 0%)\n",
            "  adding: results/models/deep_learning/imdb/distilbert/ (stored 0%)\n",
            "  adding: results/models/deep_learning/imdb/distilbert/distilbert_best.pt (deflated 12%)\n",
            "  adding: results/models/deep_learning/imdb/roberta/ (stored 0%)\n",
            "  adding: results/models/deep_learning/imdb/roberta/roberta_best.pt (deflated 12%)\n",
            "  adding: results/models/classical_ml/ (stored 0%)\n",
            "  adding: results/models/classical_ml/imdb/ (stored 0%)\n",
            "  adding: results/models/classical_ml/imdb/distilbert/ (stored 0%)\n",
            "  adding: results/models/classical_ml/imdb/distilbert/logistic_regression.pkl (deflated 23%)\n",
            "  adding: results/models/classical_ml/imdb/distilbert/random_forest.pkl (deflated 72%)\n",
            "  adding: results/models/classical_ml/imdb/distilbert/xgboost.pkl (deflated 81%)\n",
            "  adding: results/models/classical_ml/imdb/roberta/ (stored 0%)\n",
            "  adding: results/models/classical_ml/imdb/roberta/logistic_regression.pkl (deflated 23%)\n",
            "  adding: results/models/classical_ml/imdb/roberta/random_forest.pkl (deflated 72%)\n",
            "  adding: results/models/classical_ml/imdb/roberta/xgboost.pkl (deflated 81%)\n",
            "  adding: results/classical_ml/ (stored 0%)\n",
            "  adding: results/classical_ml/imdb/ (stored 0%)\n",
            "  adding: results/classical_ml/imdb/distilbert/ (stored 0%)\n",
            "  adding: results/classical_ml/imdb/distilbert/results_20251202_161900.pkl (deflated 32%)\n",
            "  adding: results/classical_ml/imdb/roberta/ (stored 0%)\n",
            "  adding: results/classical_ml/imdb/roberta/results_20251202_160315.pkl (deflated 32%)\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_91af3657-6727-43ba-a44e-380fe0f04a9d\", \"results.zip\", 2025167532)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete! Models downloaded.\n"
          ]
        }
      ],
      "source": [
        "# download trained models\n",
        "\n",
        "!zip -r results.zip results/\n",
        "from google.colab import files\n",
        "files.download('results.zip')\n",
        "\n",
        "print(\"Training complete! Models downloaded.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0207f73ce0f0410b9b68a65a72cb24e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6c18f650f8e457f8963d2ac1ecbae48",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e53d6a5f07e47028f80a12cf3dacc13",
            "value": 1
          }
        },
        "04fe72afea0b4d00898fd88557bbcdc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "059dfe3d00a847c8a6d17022f2e1a977": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "092ae5d929934c8e88bccf071ce97d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "099499c198d9464daa43a78043343619": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09ffa57211724ec98f7fb1e16116ce8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a83d7f251dc42cb8df6c72eb7ae8aab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e53d6a5f07e47028f80a12cf3dacc13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fb3f4157bbf4961a3edb1bff3f53d0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1527633ac2c14730867a78dece9491bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a88c3a1b4eb4f5da77cd58d97c0bd34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_523429b6aa624a0480b24ef1653b19e3",
              "IPY_MODEL_0207f73ce0f0410b9b68a65a72cb24e6",
              "IPY_MODEL_66fd4a879a4c419c8ca7044517d9b765"
            ],
            "layout": "IPY_MODEL_7d8d530d4a8841faa0d477f2c8fefd6a"
          }
        },
        "1a968753818e4e4da167f5d01aa959b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ba221bca29244b5be5fb5017d3fd18d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_938a73db7c4f46ff83adec5d9e0611e1",
              "IPY_MODEL_976ea2578c6a4ff9905825d9c88af369",
              "IPY_MODEL_9a83232aaf64423a972bc8e946038c4f"
            ],
            "layout": "IPY_MODEL_3720ae1316494edaa83e1b882a740a89"
          }
        },
        "1e2c4b9fc2634e62ba81d818d452598d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "235a48e224ab44c78e930972f026fb42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "263147c7f5e3499986ab689f647b8dc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27204c08d9c24d11ac6a017697cc9065": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "294826c22bfc45df902c962877d282a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "302f4f0d1f88418d83ac84735aa58fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_faf0e30e6e1049408612aa3a217b7d9a",
              "IPY_MODEL_5a49edac760149c39aa6e443f6b4df9c",
              "IPY_MODEL_4a18beecb809431b9a912aa52100aa1f"
            ],
            "layout": "IPY_MODEL_be48610c794a4ffe8468bfb61e9de690"
          }
        },
        "320796950c3a4d17a99e181f2a26393d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56c475e8323d486da25d522022f3f01e",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1527633ac2c14730867a78dece9491bd",
            "value": 50000
          }
        },
        "332e763c901c4f26bd4abbbb16b56dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3720ae1316494edaa83e1b882a740a89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "373b60fb4d354dab9a3c5b5b8d6a6fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4259dcaef5454676bd51500ba9440efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a18beecb809431b9a912aa52100aa1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eefb1ff16819499a8225d6aceeb215da",
            "placeholder": "​",
            "style": "IPY_MODEL_614b282c8b0647b0becd07ca50ce21f3",
            "value": " 25000/25000 [00:00&lt;00:00, 82459.53 examples/s]"
          }
        },
        "4ec746a93e7141d396ed22bd7af0f5e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "523429b6aa624a0480b24ef1653b19e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a968753818e4e4da167f5d01aa959b0",
            "placeholder": "​",
            "style": "IPY_MODEL_099499c198d9464daa43a78043343619",
            "value": "README.md: "
          }
        },
        "556ae0da6ce1455faf111cc60de7c964": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f98c700d3dc7444e94a64bda0e7e97a7",
            "placeholder": "​",
            "style": "IPY_MODEL_1e2c4b9fc2634e62ba81d818d452598d",
            "value": "Generating train split: 100%"
          }
        },
        "55c6c956ac1f4c90b99451081351adef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55db6a1a09ae44d89f1dde8e869e5090": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c90501e54c44498898540de0f6c6b51c",
            "placeholder": "​",
            "style": "IPY_MODEL_afbc1204da624638b59772dfdbf0b748",
            "value": " 25000/25000 [00:00&lt;00:00, 94797.06 examples/s]"
          }
        },
        "56c475e8323d486da25d522022f3f01e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a49edac760149c39aa6e443f6b4df9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f600cc705e94e7c893ace2777246b75",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c821675e7b84e26bc5dacacef7d997b",
            "value": 25000
          }
        },
        "614b282c8b0647b0becd07ca50ce21f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63aa8a58a01f447d81425315143f8f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66fd4a879a4c419c8ca7044517d9b765": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a15726d50844dc2ba75bb6d77587537",
            "placeholder": "​",
            "style": "IPY_MODEL_6dce79a204114260b115eb439a71e9e7",
            "value": " 7.81k/? [00:00&lt;00:00, 393kB/s]"
          }
        },
        "680c143cfb6f40028002bb07b51cfcee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b81871f7e76a4d24ab1c6d907bb5e34e",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_373b60fb4d354dab9a3c5b5b8d6a6fd6",
            "value": 25000
          }
        },
        "6af89e966b074b75bddfcca0bf0e80e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8da7c2d2e5c043e4ac2a3bd9a8d920c6",
            "placeholder": "​",
            "style": "IPY_MODEL_04fe72afea0b4d00898fd88557bbcdc4",
            "value": " 20.5M/20.5M [00:00&lt;00:00, 198kB/s]"
          }
        },
        "6c821675e7b84e26bc5dacacef7d997b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dce79a204114260b115eb439a71e9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f600cc705e94e7c893ace2777246b75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78ba506d7c914572a3e2e2261e06e688": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27204c08d9c24d11ac6a017697cc9065",
            "placeholder": "​",
            "style": "IPY_MODEL_332e763c901c4f26bd4abbbb16b56dd7",
            "value": "plain_text/test-00000-of-00001.parquet: 100%"
          }
        },
        "7a15726d50844dc2ba75bb6d77587537": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d0db30d0ac84ac5a48b662afd65325b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d8d530d4a8841faa0d477f2c8fefd6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80323394f03d46c9862ab6d1ca0b9324": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83e1fc4837d549d9b8c9c3cc7af05654": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55c6c956ac1f4c90b99451081351adef",
            "placeholder": "​",
            "style": "IPY_MODEL_80323394f03d46c9862ab6d1ca0b9324",
            "value": " 21.0M/21.0M [00:00&lt;00:00, 49.1MB/s]"
          }
        },
        "862cc9b18dd24cc5aed4f8820ebc8ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8da7c2d2e5c043e4ac2a3bd9a8d920c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "938a73db7c4f46ff83adec5d9e0611e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7b72a9514e846e38281b1ce104dd698",
            "placeholder": "​",
            "style": "IPY_MODEL_235a48e224ab44c78e930972f026fb42",
            "value": "plain_text/unsupervised-00000-of-00001.p(…): 100%"
          }
        },
        "976ea2578c6a4ff9905825d9c88af369": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a4e71cfd2cb4912a3e9e6b270911706",
            "max": 41996509,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_294826c22bfc45df902c962877d282a0",
            "value": 41996509
          }
        },
        "9a4470cbc07e425c9965a66e9c95264e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a4e71cfd2cb4912a3e9e6b270911706": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a83232aaf64423a972bc8e946038c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ec746a93e7141d396ed22bd7af0f5e9",
            "placeholder": "​",
            "style": "IPY_MODEL_ca10e6dbb14c43219d350e80181eb481",
            "value": " 42.0M/42.0M [00:00&lt;00:00, 43.6MB/s]"
          }
        },
        "9e24b077d2554c7487b9a67ae27f2d67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e57f585de484a0bbd9ffe99315ff198": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09ffa57211724ec98f7fb1e16116ce8a",
            "max": 20979968,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_092ae5d929934c8e88bccf071ce97d64",
            "value": 20979968
          }
        },
        "a6c18f650f8e457f8963d2ac1ecbae48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ade29563d8cd415bb234fd80266ffada": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3fd8c8eed624af3afecaa5f3d1d8db0",
            "placeholder": "​",
            "style": "IPY_MODEL_4259dcaef5454676bd51500ba9440efd",
            "value": "Generating unsupervised split: 100%"
          }
        },
        "afbc1204da624638b59772dfdbf0b748": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1dc323a3b5048e38a5017c169474a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_263147c7f5e3499986ab689f647b8dc7",
            "placeholder": "​",
            "style": "IPY_MODEL_63aa8a58a01f447d81425315143f8f52",
            "value": " 50000/50000 [00:00&lt;00:00, 149373.32 examples/s]"
          }
        },
        "b81871f7e76a4d24ab1c6d907bb5e34e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be48610c794a4ffe8468bfb61e9de690": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6c6fb8437344853ad45276a32ea6e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_556ae0da6ce1455faf111cc60de7c964",
              "IPY_MODEL_680c143cfb6f40028002bb07b51cfcee",
              "IPY_MODEL_55db6a1a09ae44d89f1dde8e869e5090"
            ],
            "layout": "IPY_MODEL_0fb3f4157bbf4961a3edb1bff3f53d0e"
          }
        },
        "c90501e54c44498898540de0f6c6b51c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca10e6dbb14c43219d350e80181eb481": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca8cf4fba00b478786dbad16aaeb35fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ade29563d8cd415bb234fd80266ffada",
              "IPY_MODEL_320796950c3a4d17a99e181f2a26393d",
              "IPY_MODEL_b1dc323a3b5048e38a5017c169474a29"
            ],
            "layout": "IPY_MODEL_fb5c9a41d33b4bb796a3cd629908743e"
          }
        },
        "d33443e6a1b64581b6be8a95a623e6b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e559284867cf47ed958e0f9d86b7fe72",
              "IPY_MODEL_9e57f585de484a0bbd9ffe99315ff198",
              "IPY_MODEL_83e1fc4837d549d9b8c9c3cc7af05654"
            ],
            "layout": "IPY_MODEL_0a83d7f251dc42cb8df6c72eb7ae8aab"
          }
        },
        "d3fd8c8eed624af3afecaa5f3d1d8db0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6ccaa4056bc48c9b591164d568ae002": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e559284867cf47ed958e0f9d86b7fe72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e24b077d2554c7487b9a67ae27f2d67",
            "placeholder": "​",
            "style": "IPY_MODEL_059dfe3d00a847c8a6d17022f2e1a977",
            "value": "plain_text/train-00000-of-00001.parquet: 100%"
          }
        },
        "eefb1ff16819499a8225d6aceeb215da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f191517558e6419293ad4542aa70dbbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ccaa4056bc48c9b591164d568ae002",
            "max": 20470363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a4470cbc07e425c9965a66e9c95264e",
            "value": 20470363
          }
        },
        "f2d44aae8dd24d9080213f186677c05f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7b72a9514e846e38281b1ce104dd698": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f98c700d3dc7444e94a64bda0e7e97a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf0e30e6e1049408612aa3a217b7d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2d44aae8dd24d9080213f186677c05f",
            "placeholder": "​",
            "style": "IPY_MODEL_862cc9b18dd24cc5aed4f8820ebc8ca2",
            "value": "Generating test split: 100%"
          }
        },
        "fb5477d1c8c64562834acd33bfc014ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78ba506d7c914572a3e2e2261e06e688",
              "IPY_MODEL_f191517558e6419293ad4542aa70dbbe",
              "IPY_MODEL_6af89e966b074b75bddfcca0bf0e80e6"
            ],
            "layout": "IPY_MODEL_7d0db30d0ac84ac5a48b662afd65325b"
          }
        },
        "fb5c9a41d33b4bb796a3cd629908743e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
